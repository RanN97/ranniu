{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/venv_1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchmetrics\n",
    "import ast\n",
    "import random\n",
    "import transformers\n",
    "from transformers import GPT2Config, GPT2Model\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import tree\n",
    "import functions\n",
    "from functions import Dataset_create_embeddings_from_tokens_for_text, Clinical_Bert_Model, Dataset_create_embeddings_from_classdescripsion_for_classsentence_list\n",
    "import sequence_label\n",
    "import wandb\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import multiprocessing as mp\n",
    "import argparse_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse_para.arg_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1391/1391 [00:00<00:00, 30567.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease = tree.build_a_tree()\n",
    "# build the tree, it is four dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b', ignore_mismatched_sizes=True)\n",
    "clinical_DS_bert = transformers.BertModel.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b')\n",
    "# get the pre-trained bert model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print('GPU', torch.cuda.is_available())\n",
    "\n",
    "clinical_Bert_Model = Clinical_Bert_Model(clinical_DS_bert=clinical_DS_bert)\n",
    "clinical_Bert_Model = clinical_Bert_Model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15978/15978 [03:14<00:00, 82.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of class_embedding_tensor is:  torch.Size([15978, 768])\n",
      "the length of class embedding is(end tokens not included) 15978\n"
     ]
    }
   ],
   "source": [
    "# this dataframe contains the incd9 classes embeddings\n",
    "\n",
    "df_classes_descripsion = functions.create_classes_descripsions(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# df_classes_descripsion_embeddings has two columns: 'classes' and 'descripsion', and the length of it is all the category and subclass(end tokens not included).\n",
    "\n",
    "class_input_ids_tensor = functions.create_class_bert_tokens(df_classes_descripsion, tokenizer)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "class_input_ids_tensor = class_input_ids_tensor.detach()\n",
    "create_class_embeddings_dataset = Dataset_create_embeddings_from_classdescripsion_for_classsentence_list(class_input_ids_tensor)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "create_class_embeddings_dataloader = DataLoader(create_class_embeddings_dataset, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "class_embeddings_tensor = functions.create_classes_embeddings(create_class_embeddings_dataloader, clinical_Bert_Model, device)\n",
    "print('the shape of class_embedding_tensor is: ', class_embeddings_tensor.shape)\n",
    "class_embeddings_dict = functions.create_class_embeddings_dict(list(df_classes_descripsion['classes']), class_embeddings_tensor)\n",
    "print('the length of class embedding is(end tokens not included)',len(class_embeddings_dict))\n",
    "# keys are classes and values are embeddings tensors, and the length of it is all the category and subclass(end tokens not included).\n",
    "# the shape of embeddings is (n, 768)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(class_embeddings_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_top500 = pd.read_csv('./data/top500_datasets/trainset_top500_new.csv').iloc[:32]\n",
    "df_validation_top500 = pd.read_csv('./data/top500_datasets/validationset_top500_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/htc_mimic3/functions.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '', dataframe['TEXT'].iloc[i])  # delete [**      **]\n",
      "/u/home/niur/htc_mimic3/functions.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}', '', dataframe['TEXT'].iloc[i])  # delete 12:11\n",
      "/u/home/niur/htc_mimic3/functions.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}AM', '', dataframe['TEXT'].iloc[i])  # delete 12:11AM\n",
      "/u/home/niur/htc_mimic3/functions.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}PM', '', dataframe['TEXT'].iloc[i])  # delete 12:11PM\n",
      "/u/home/niur/htc_mimic3/functions.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('==+', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(' +', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('# *', ' ', dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('\\n.\\n', '\\n\\n', dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = dataframe['TEXT'].iloc[i].split('\\n\\n')\n",
      "/u/home/niur/htc_mimic3/functions.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = temp\n",
      "/u/home/niur/htc_mimic3/functions.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(\"(Admission Date:)|(Discharge Date:)|(Service:)|(Date of Birth:)|(Sex:)|(Attending:)|(Provider:)|(Name:)|(Date/Time:)|(MD Phone:)|(Completed by:)|(Job#:)|(Dictated By:)|(D: )|(T: )|(JOB :)\", \"\", dataframe['TEXT'].iloc[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HADM_ID', 'TEXT', 'ICD9_CODE', 'SEQUENCIAL_LABEL'], dtype='object')\n",
      "(32, 4) (1468, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train_top500 = functions.text_cleaning(df_train_top500)\n",
    "df_validation_top500 = functions.text_cleaning(df_validation_top500)\n",
    "df_train_top500 = functions.convert_icdstr_to_list(df_train_top500)\n",
    "df_validation_top500 = functions.convert_icdstr_to_list(df_validation_top500)\n",
    "df_train_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_train_top500)\n",
    "df_validation_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_validation_top500)\n",
    "print(df_train_top500.columns)\n",
    "print(df_train_top500.shape, df_validation_top500.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 32.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train token shape: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1468/1468 [00:46<00:00, 31.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid token shape: 1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ids_list_train = functions.create_text_tokens(df_train_top500, tokenizer) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "# input_ids_list_train = input_ids_list_train.detach()\n",
    "print('train token shape:', len(input_ids_list_train))\n",
    "input_ids_list_validation = functions.create_text_tokens(df_validation_top500, tokenizer) # , token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "# input_ids_list_validation = input_ids_list_validation.detach()\n",
    "print('valid token shape:', len(input_ids_list_validation))\n",
    "\n",
    "# train_dataset_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_train) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "# validation_datasdet_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_validation) #, token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "# train_dataloader_top500_create_text_embeddings = DataLoader(train_dataset_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "# validation_dataloader_top500_create_text_embeddings = DataLoader(validation_datasdet_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "\n",
    "\n",
    "# train_text_embeddings_tensor = functions.create_text_embeddings(train_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# validation_text_embeddings_tensor = functions.create_text_embeddings(validation_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# # this is the outputs of encoder and will be the cross attention input of decoder.\n",
    "# print('train text embedding shape:', train_text_embeddings_tensor.shape)\n",
    "# print('valid text embedding shape:', validation_text_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of mask dict is: 17392\n"
     ]
    }
   ],
   "source": [
    "mask_dict = functions.create_tokens_mask_dict(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# it s a dictionary contains the -inf and 0 mask(1d tensor) of each category and subclass.\n",
    "class_label_index_dict = functions.create_class_label_index_dict(mask_dict)\n",
    "# {'start':0, .......}\n",
    "index_to_class_label_dict = functions.create_index_to_class_label_dict(mask_dict)\n",
    "# {0:'start', .......}\n",
    "print('the length of mask dict is:',len(class_label_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequencial_label_list = list(df_train_top500['SEQUENCIAL_LABEL'])       # [[L], [L], [L]......]\n",
    "valiation_sequencial_label_list = list(df_validation_top500['SEQUENCIAL_LABEL'])\n",
    "# here the data pass into the dataset can not be tensors, because change into embeddings need the complete class embedding dict.\n",
    "\n",
    "train_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, train_sequencial_label_list)  # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "validation_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, valiation_sequencial_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_transformer(Dataset):\n",
    "    def __init__(self, input_ids_list_train, label_index_list):\n",
    "        self.input_ids_list_train = input_ids_list_train   #[(n,128), (n,128), (n,128), (n,128), (n,128), (n,128), (n,128)]\n",
    "        self.label_index_list = label_index_list      # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids_list_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids_list_train[index], self.label_index_list[index]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch_input_ids_list = [item[0] for item in batch]  #[(n,128), (n,128), (n,128), (n,128), (n,128), (n,128), (n,128)]\n",
    "    batch_input_ids_tensor = torch.nn.utils.rnn.pad_sequence(batch_input_ids_list, batch_first=True)  # (b,n,128)  n is the largest number of sentences in a samples batch.\n",
    "    encoder_output_mask = []\n",
    "    for item in batch_input_ids_list:\n",
    "        single_mask = torch.tensor([0]*batch_input_ids_tensor.shape[1])  # masked is 0\n",
    "        single_mask[:item.shape[0]] = 1    # not masked is 1\n",
    "        encoder_output_mask.append(single_mask)\n",
    "    encoder_output_mask = torch.stack(encoder_output_mask) # (b,n)\n",
    "    \n",
    "    \n",
    "    batch_label_index = torch.nn.utils.rnn.pad_sequence([item[1] for item in batch], batch_first=True, padding_value=17391)  # (b,L) L is the largest length in this batch\n",
    "    max_L = batch_label_index.shape[1]\n",
    "    padding_mask = []\n",
    "    for item in batch:\n",
    "        single_mask = torch.tensor([0]*max_L)  # masked is 0\n",
    "        true_L = item[1].shape[0]\n",
    "        single_mask[:true_L] = 1    # not masked is 1\n",
    "        padding_mask.append(single_mask)\n",
    "    padding_mask = torch.stack(padding_mask)   # (b,L) L is the largest length in this batch   (1,0)\n",
    "\n",
    "    \n",
    "    return batch_input_ids_tensor, encoder_output_mask, batch_label_index, padding_mask     #  (b,n,128) (b,n) (b,L) (b,L)  L is the largest length in this batch \n",
    "\n",
    "\n",
    "train_dataset = Dataset_transformer(input_ids_list_train, train_label_index_list)\n",
    "validation_dataset = Dataset_transformer(input_ids_list_validation, validation_label_index_list)\n",
    "batch_size_transformer = args.batch_size_transformer\n",
    "num_workers = args.num_workers\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size_transformer, shuffle=True, drop_last=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)  \n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=batch_size_transformer, shuffle=False, drop_last=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
    "decoder_num_layers = args.decoder_num_layers\n",
    "transformer_dropout = args.transformer_dropout\n",
    "transformer_nhead = args.transformer_nhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer_Model, self).__init__()\n",
    "\n",
    "        self.clinical_bert = clinical_DS_bert\n",
    "        for lay in self.clinical_bert.encoder.layer[args.bert_freeze_layerindex_start:args.bert_freeze_layerindex_end+1]:\n",
    "            for para in lay.parameters():\n",
    "                para.requires_grad = False\n",
    "\n",
    "        self.class_embeddings_start = torch.nn.Parameter(torch.randn(768))\n",
    "        self.class_embeddings_end_start = torch.nn.Parameter(torch.randn(768))\n",
    "        \n",
    "        self.gpt2config = transformers.GPT2Config(n_embd=768, n_layer=decoder_num_layers, n_head=transformer_nhead, add_cross_attention=True, n_positions=6670)\n",
    "        self.gpt2model = torch.nn.ModuleList([transformers.models.gpt2.modeling_gpt2.GPT2Block(self.gpt2config) for i in range(self.gpt2config.num_hidden_layers)])\n",
    "\n",
    "        # self.decoder_layer = torch.nn.TransformerDecoderLayer(d_model=768, nhead=transformer_nhead, dropout=transformer_dropout, activation='gelu', batch_first=True)\n",
    "        # self.transformer_decoder = torch.nn.TransformerDecoder(self.decoder_layer, num_layers=decoder_num_layers)  # forward padding mask(N,L)  attention causal mask(L,L)  multiheadattention  is_causal\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.linear2 = torch.nn.Linear(768, 768)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, class_embeddings_dict, mask_dict, batch_input_ids_tensor, batch_label_index, batch_padding_mask, encoder_output_mask):   #  (b,n,128), (b,L)  (b,L)  (b,n)\n",
    "\n",
    "        class_embeddings_dict = functions.add_end_classes_embeddings(class_embeddings_dict, self.class_embeddings_start, self.class_embeddings_end_start, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, device)\n",
    "        class_embedding_list = []\n",
    "        for item in list(mask_dict.keys())[:-1]:\n",
    "            class_embedding_list.append(class_embeddings_dict[item])\n",
    "        class_embeddings_tensor = torch.stack(class_embedding_list)    # (C,768) C:17391\n",
    "\n",
    "        label_embedding_tensor = functions.convert_sequencial_label_to_embedding_tensor(batch_label_index, class_embeddings_dict, index_to_class_label_dict)  # (b,L) --> (b,L,768)\n",
    "        \n",
    "        batch_text_embedding_tensor = torch.stack([self.clinical_bert(single_input_ids_tensor)['last_hidden_state'][:,0,:] for single_input_ids_tensor in batch_input_ids_tensor])   # (b,n,768)\n",
    "        batch_padding_mask = batch_padding_mask[:,None,:,None]\n",
    "        encoder_output_mask = encoder_output_mask[:,None,None,:]\n",
    "\n",
    "        for i, block in enumerate(self.gpt2model):\n",
    "            gpt2model_output = block(label_embedding_tensor, layer_past=None, attention_mask=batch_padding_mask,\n",
    "                                encoder_hidden_states=batch_text_embedding_tensor, encoder_attention_mask=encoder_output_mask, use_cache=True)[0]#  (b,L,768)  (b,n,768) -->  (b,L,768)\n",
    "\n",
    "\n",
    "        transformer_output = self.linear1(gpt2model_output)   #  (b,L,768)\n",
    "        transformer_output = self.gelu(transformer_output)\n",
    "        transformer_output = self.linear2(transformer_output)  #  (b,L,768)\n",
    "\n",
    "        transformer_output = torch.nn.functional.normalize(transformer_output, dim=-1)  # (b,L,768)\n",
    "        class_embeddings_tensor = torch.nn.functional.normalize(class_embeddings_tensor, dim=-1)  #  (C,768)\n",
    "\n",
    "\n",
    "        score_tensor = torch.matmul(transformer_output, class_embeddings_tensor.T).to(dtype=torch.float16)  # (b,L,768), (768,C)  -->  (b,L,C)\n",
    "        batch_mask_list = []\n",
    "        for item in batch_label_index:  # (b,L)\n",
    "            batch_mask_list.append(torch.stack([mask_dict[index_to_class_label_dict[index.item()]] for index in item]))   # (L,C)\n",
    "        batch_mask_tensor = torch.stack(batch_mask_list)   # (b,L,C)\n",
    "        batch_mask_tensor = batch_mask_tensor.to(device)\n",
    "        logits = (score_tensor+batch_mask_tensor)   # (b,L,C)\n",
    "        return logits  # (b,L,C)\n",
    "    \n",
    "    def forward_valid(self, class_embeddings_dict, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor, batch_label_index, encoder_output_mask, past_key_values):   #  (1,n,768), (1,L)  (1,L)  (1,n)\n",
    "\n",
    "\n",
    "        label_embedding_tensor = functions.convert_sequencial_label_to_embedding_tensor(batch_label_index, class_embeddings_dict, index_to_class_label_dict)  # (1,L) --> (1,L,768)\n",
    "        \n",
    "        past_key_values_temp = []\n",
    "        encoder_output_mask = encoder_output_mask[:,None,None,:]\n",
    "        if not past_key_values:\n",
    "            for i, block in enumerate(self.gpt2model):\n",
    "                gpt2model_output = block(label_embedding_tensor, layer_past=None, attention_mask=None,\n",
    "                                encoder_hidden_states=batch_text_embedding_tensor, encoder_attention_mask=encoder_output_mask, use_cache=True)  # (1,L,768)  (1,n,768) -->  (1,L,768)\n",
    "\n",
    "                past_key_values_temp.append(gpt2model_output[1])\n",
    "\n",
    "        else:\n",
    "            for i, (layer_past, block) in enumerate(zip(past_key_values, self.gpt2model)):\n",
    "                # layer_past = tuple(past_state.to(device) for past_state in layer_past)\n",
    "                gpt2model_output = block(label_embedding_tensor, layer_past=layer_past, attention_mask=None,\n",
    "                                encoder_hidden_states=batch_text_embedding_tensor, encoder_attention_mask=encoder_output_mask, use_cache=True)  # (1,L,768)  (1,n,768) -->  (1,L,768)\n",
    "                # print(gpt2model_output[1][0].shape)\n",
    "                past_key_values_temp.append(gpt2model_output[1])\n",
    "\n",
    "        transformer_output = self.linear1(gpt2model_output[0])   #  (1,L,768)\n",
    "        transformer_output = self.gelu(transformer_output)\n",
    "        transformer_output = self.linear2(transformer_output)  #  (1,L,768)\n",
    "        transformer_output = torch.nn.functional.normalize(transformer_output, dim=-1)  # (1,L,768)\n",
    "        class_embeddings_tensor = torch.nn.functional.normalize(class_embeddings_tensor, dim=-1)  #  (C,768)\n",
    "\n",
    "        \n",
    "        score_tensor = torch.matmul(transformer_output, class_embeddings_tensor.T).to(dtype=torch.float16)  # (1,L,768), (768,C)  -->  (1,L,C)\n",
    "        batch_mask_list = []\n",
    "        for item in batch_label_index:  # (b,L)\n",
    "            batch_mask_list.append(torch.stack([mask_dict[index_to_class_label_dict[index.item()]] for index in item]))   # (L,C)\n",
    "        batch_mask_tensor = torch.stack(batch_mask_list)   # (1,L,C)\n",
    "        batch_mask_tensor = batch_mask_tensor.to(device)\n",
    "        logits = (score_tensor+batch_mask_tensor)   # (1,L,C)\n",
    "        return logits, past_key_values_temp  # (1,L,C)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = Transformer_Model()\n",
    "transformer_model = transformer_model.to(device)\n",
    "learning_rate = args.learning_rate\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum', ignore_index=17391)    # when compute, the size must be (N, C, L) and (N, L)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=learning_rate, weight_decay=args.adam_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask):\n",
    "    predicted_index_list = []\n",
    "    predicted_token_list = []\n",
    "    predicted_token_probabiluty_list = []\n",
    "    input_token_index_list = [class_label_index_dict['start']]\n",
    "    end_start_index_label = class_label_index_dict['/start']\n",
    "    batch_text_embedding_tensor = torch.stack([transformer_model.clinical_bert(single_input_ids_tensor)['last_hidden_state'][:,0,:] for single_input_ids_tensor in single_input_ids_tensor_valid])   # (1,n,768)\n",
    "    past_key_values = None\n",
    "    while input_token_index_list[-1] != end_start_index_label:\n",
    "        logits, past_key_values = transformer_model.forward_valid(class_embeddings_dict_valid, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor=batch_text_embedding_tensor, batch_label_index=torch.tensor([input_token_index_list]).to(device, non_blocking=True), encoder_output_mask=single_encoder_output_mask, past_key_values=past_key_values)   # (1,n,768), (1,L) --> (1,L,C)\n",
    "        predicted_index = torch.argmax(logits.squeeze(0), dim=-1)[-1].item()   # (1,L,C)-->int\n",
    "        predicted_token_probabiluty_list.append(logits.squeeze(0)[-1])  # (1,L,C) -->[L,(C)]\n",
    "        predicted_index_list.append(predicted_index)   # [L]\n",
    "        predicted_token_list.append(index_to_class_label_dict[predicted_index])  # [L]\n",
    "        input_token_index_list.append(predicted_index)   # [L]\n",
    "\n",
    "        if len(predicted_token_list) > 114:\n",
    "            break\n",
    "    return predicted_token_probabiluty_list, predicted_index_list, predicted_token_list\n",
    "\n",
    "\n",
    "def beam_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask, beam_size=args.beam_size):  # (1,n,128)  (1,n)\n",
    "    predicted_index_list = [[] for _ in range(beam_size)]\n",
    "    predicted_token_probabiluty_list = [[] for _ in range(beam_size)]\n",
    "    input_token_index_tensor = torch.tensor([[class_label_index_dict['start']]]).to(device, non_blocking=True)   # (1,1)\n",
    "    end_start_index_label = class_label_index_dict['/start']\n",
    "    batch_text_embedding_tensor = torch.stack([transformer_model.clinical_bert(single_input_ids_tensor)['last_hidden_state'][:,0,:] for single_input_ids_tensor in single_input_ids_tensor_valid])   # (1,n,768)\n",
    "    past_key_values = None\n",
    "    logits, past_key_values = transformer_model.forward_valid(class_embeddings_dict_valid, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor=batch_text_embedding_tensor, batch_label_index=input_token_index_tensor, encoder_output_mask=single_encoder_output_mask, past_key_values=past_key_values)   # (1,n,768), (1,1) --> (1,1,C)    ((1, n_head, 1, 768/n_head), (1, n_head, 1, 768/n_head))*n_layers\n",
    "    for i in range(len(past_key_values)):\n",
    "        past_key_values[i] = list(past_key_values[i])\n",
    "        past_key_values[i][0] = past_key_values[i][0].repeat((beam_size, 1, 1, 1))\n",
    "        past_key_values[i][1] = past_key_values[i][1].repeat((beam_size, 1, 1, 1))\n",
    "        past_key_values[i] = tuple(past_key_values[i])\n",
    "    top = torch.topk(logits.squeeze(), beam_size, dim=-1)\n",
    "    predicted_index = top[1]  # tensor (beam)\n",
    "    predicted_prob_accumu = top[0]  # tensor (beam)\n",
    "    for i in range(beam_size):\n",
    "        predicted_index_list[i].append(predicted_index[i])\n",
    "        predicted_token_probabiluty_list[i].append(predicted_prob_accumu[i])\n",
    "        # predicted_token_list[i].append(index_to_class_label_dict[predicted_index[i]])\n",
    "    batch_text_embedding_tensor = batch_text_embedding_tensor.repeat((beam_size, 1, 1))    # (beam,n,768)\n",
    "    single_encoder_output_mask = single_encoder_output_mask.repeat((beam_size, 1))   # (beam, n)\n",
    "    input_token_index_tensor = predicted_index.reshape((beam_size,1))   # (beam,1)\n",
    "    while not input_token_index_tensor[:,-1].to(device).equal(torch.tensor([end_start_index_label]*beam_size).to(device)):\n",
    "        logits, past_key_values = transformer_model.forward_valid(class_embeddings_dict_valid, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor=batch_text_embedding_tensor, batch_label_index=input_token_index_tensor, encoder_output_mask=single_encoder_output_mask, past_key_values=past_key_values)   # (beam,n,768), (beam,L) --> (beam,L,C)\n",
    "        logits = torch.nn.Softmax(dim=-1)(logits[:,-1,:])  # (beam, C)\n",
    "        predicted_prob_single = logits  # (beam, C)\n",
    "        logits = logits * predicted_prob_accumu.reshape((beam_size,1))\n",
    "        top = torch.topk(logits.view(-1), beam_size)  # (beam*C)-->(beam)\n",
    "        predicted_index = top[1]\n",
    "        predicted_prob_accumu = top[0]\n",
    "        come_from = torch.div(predicted_index, 17391, rounding_mode='floor')\n",
    "        predicted_index = predicted_index % 17391\n",
    "        past_kv_temp = past_key_values.copy()\n",
    "        predicted_index_list_temp = predicted_index_list.copy()\n",
    "        predicted_token_probabiluty_list_temp = predicted_token_probabiluty_list.copy()\n",
    "        for i in range(beam_size):\n",
    "            predicted_index_list[i] = predicted_index_list_temp[come_from[i]] + [predicted_index[i]]\n",
    "            predicted_token_probabiluty_list[i] = predicted_token_probabiluty_list_temp[come_from[i]] + [predicted_prob_single[come_from[i]][predicted_index[i]]]\n",
    "            for j in range(args.decoder_num_layers):\n",
    "                past_key_values[j][0][i] = past_kv_temp[j][0][come_from[i]]\n",
    "                past_key_values[j][1][i] = past_kv_temp[j][1][come_from[i]]\n",
    "        input_token_index_tensor = [[] for _ in range(beam_size)]\n",
    "        for i in range(beam_size):\n",
    "            input_token_index_tensor[i] = torch.tensor(predicted_index_list[i])\n",
    "        input_token_index_tensor = torch.stack(input_token_index_tensor)\n",
    "        if input_token_index_tensor.shape[1] > 114:\n",
    "            break\n",
    "        # print(len(predicted_token_probabiluty_list[0]), len(predicted_index_list[0]))\n",
    "    predicted_index_list = predicted_index_list[0]\n",
    "    cut_index = predicted_index_list.index(end_start_index_label) if end_start_index_label in predicted_index_list else len(predicted_index_list)\n",
    "    predicted_index_list = predicted_index_list[:cut_index+1]\n",
    "    predicted_token_list = [index_to_class_label_dict[int(i)] for i in predicted_index_list]\n",
    "    predicted_token_probabiluty_list = predicted_token_probabiluty_list[0][:cut_index+1]\n",
    "    return predicted_token_probabiluty_list, predicted_index_list, predicted_token_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(validation_dataloader):\n",
    "    transformer_model.eval()\n",
    "    print('Validation start...')\n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        category_accuracy = 0\n",
    "        first_class_accuracy = 0\n",
    "        second_class_accuracy = 0\n",
    "        disease_accuracy = 0\n",
    "        label_f1_0_1_tensor = torch.tensor([])\n",
    "        predicted_f1_0_1_tensor = torch.tensor([])\n",
    "        label_AUROC_tesnor = torch.tensor([],dtype=int).to(device)\n",
    "        predicted_AUROC_tensor = torch.tensor([]).to(device)\n",
    "        random_outout_index = random.randint(0,1000)\n",
    "\n",
    "        class_embeddings_dict_valid = functions.add_end_classes_embeddings(class_embeddings_dict, transformer_model.class_embeddings_start, transformer_model.class_embeddings_end_start, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, device)\n",
    "        class_embedding_list = []\n",
    "        for item in list(mask_dict.keys())[:-1]:\n",
    "            class_embedding_list.append(class_embeddings_dict_valid[item])\n",
    "        class_embeddings_tensor = torch.stack(class_embedding_list)    # (C,768) C:17391\n",
    "        print(class_embeddings_tensor.shape)\n",
    "\n",
    "        for i, (batch_input_ids_tensor, batch_encoder_output_mask, batch_label_index, batch_padding_mask) in tqdm(enumerate(validation_dataloader)):\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                batch_input_ids_tensor = batch_input_ids_tensor.to(device, non_blocking=True)\n",
    "                batch_label_index = batch_label_index.to(device, non_blocking=True)\n",
    "                batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)\n",
    "                batch_encoder_output_mask = batch_encoder_output_mask.to(device, non_blocking=True)\n",
    "                # attention_mask_valid = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)   # masked is True, not masked is False\n",
    "                \n",
    "\n",
    "                batch_logits = transformer_model(class_embeddings_dict_valid, mask_dict, batch_input_ids_tensor=batch_input_ids_tensor, batch_label_index=batch_label_index, batch_padding_mask=batch_padding_mask, encoder_output_mask=batch_encoder_output_mask)   # (b,n,128), (b,L) --> (b,L,C)\n",
    "                batch_logits = batch_logits.permute((0,2,1))   # --> (b,C,L)\n",
    "                end_start_index_label = class_label_index_dict['/start'] \n",
    "                lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "                validation_loss += criterion(batch_logits, lable_for_loss_tensor)\n",
    "\n",
    "                for j in range(batch_input_ids_tensor.shape[0]):\n",
    "                    single_input_ids_tensor_valid = batch_input_ids_tensor[j].unsqueeze(0)   # (1,n,128)\n",
    "                    single_encoder_output_mask = batch_encoder_output_mask[j].unsqueeze(0)  # (1,n)\n",
    "\n",
    "                    single_label_index_list = batch_label_index[j].tolist()    # [L]\n",
    "                    padding_index = single_label_index_list.index(17391) if 17391 in single_label_index_list else len(single_label_index_list)\n",
    "                    single_label_index_list = single_label_index_list[:padding_index]\n",
    "                    single_sequencial_label = [index_to_class_label_dict[index] for index in single_label_index_list]\n",
    "\n",
    "                    # ingle_label_index_tensor = label_index_list[j].unsqueeze(0)    # (1,L)\n",
    "                    # single_text_embedding_tensor = single_text_embedding_tensor.to(device)\n",
    "                    # single_label_index_tensor = single_label_index_tensor.to(device)\n",
    "\n",
    "                    if args.generative_strategy == 'greedy_search':\n",
    "                        predicted_token_probabiluty_list, predicted_index_list, predicted_token_list = greedy_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask)\n",
    "                    elif args.generative_strategy == 'beam_search':\n",
    "                        predicted_token_probabiluty_list, predicted_index_list, predicted_token_list = beam_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask)\n",
    "                    # predicted_index_list = []\n",
    "                    # predicted_token_list = []\n",
    "                    # predicted_token_probabiluty_list = []\n",
    "                    # input_token_index_list = [class_label_index_dict['start']]\n",
    "                    # end_start_index_label = class_label_index_dict['/start']\n",
    "                    # batch_text_embedding_tensor = torch.stack([transformer_model.clinical_bert(single_input_ids_tensor)['last_hidden_state'][:,0,:] for single_input_ids_tensor in single_input_ids_tensor_valid])   # (b,n,768)\n",
    "                    # past_key_values = None\n",
    "                    # while input_token_index_list[-1] != end_start_index_label:\n",
    "                    #     logits, past_key_values = transformer_model.forward_valid(class_embeddings_dict_valid, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor=batch_text_embedding_tensor, batch_label_index=torch.tensor([input_token_index_list]).to(device, non_blocking=True), encoder_output_mask=single_encoder_output_mask, past_key_values=past_key_values)   # (1,n,128), (1,L) --> (1,L,C)\n",
    "                    #     predicted_index = torch.argmax(logits.squeeze(0), dim=-1)[-1].item()   # (1,L,C)-->int\n",
    "                    #     predicted_token_probabiluty_list.append(logits.squeeze(0)[-1])  # (1,L,C) -->[L,(C)]\n",
    "                    #     predicted_index_list.append(predicted_index)   # [L]\n",
    "                    #     predicted_token_list.append(index_to_class_label_dict[predicted_index])  # [L]\n",
    "                    #     input_token_index_list.append(predicted_index)   # [L]\n",
    "\n",
    "                    #     if len(predicted_token_list) > 114:\n",
    "                    #         break\n",
    "\n",
    "                    if args.generative_strategy == 'greedy_search':\n",
    "                        predicted_token_probabiluty_tensor = torch.nn.Softmax(dim=-1)(torch.stack(predicted_token_probabiluty_list))  # (L,C)\n",
    "                        single_probability_AUROC_predicted, single_label_AUROC_0_1_tensor = functions.create_probability_tensor_for_AUROC(single_sequencial_label, class_label_index_dict, predicted_token_probabiluty_tensor, predicted_index_list, device)\n",
    "                    elif args.generative_strategy == 'beam_search':\n",
    "                        single_probability_AUROC_predicted = torch.tensor([0.0]*17391, dtype=torch.float).to(device, non_blocking=True)\n",
    "                        single_probability_AUROC_predicted[predicted_index_list] = torch.tensor(predicted_token_probabiluty_list, dtype=torch.float).to(device, non_blocking=True)\n",
    "                        class_list = list(class_label_index_dict.keys())\n",
    "                        single_label_AUROC_0_1_tensor = torch.tensor([0]*17391)\n",
    "                        for k in single_sequencial_label:\n",
    "                            index = class_list.index(k)\n",
    "                            single_label_AUROC_0_1_tensor[index] = 1\n",
    "\n",
    "                    predicted_category_tokens_list, predicted_first_class_tokens_list, predicted_second_class_tokens_list, predicted_disease_tokens_list = functions.split_predicted_class_tokens(predicted_token_list, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                    label_category_tokens_list, label_first_class_tokens_list, label_second_class_tokens_list, label_disease_tokens_list = functions.split_predicted_class_tokens(single_sequencial_label, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                    category_accuracy += (len(set(predicted_category_tokens_list).intersection(set(label_category_tokens_list))) / max(len(predicted_category_tokens_list), len(label_category_tokens_list)))\n",
    "                    first_class_accuracy += (len(set(predicted_first_class_tokens_list).intersection(set(label_first_class_tokens_list))) / max(len(predicted_first_class_tokens_list), len(label_first_class_tokens_list)))\n",
    "                    second_class_accuracy += (len(set(predicted_second_class_tokens_list).intersection(set(label_second_class_tokens_list))) / max(len(predicted_second_class_tokens_list), len(label_second_class_tokens_list)))\n",
    "                    disease_accuracy += (len(set(predicted_disease_tokens_list).intersection(set(label_disease_tokens_list))) / max(len(predicted_disease_tokens_list), len(label_disease_tokens_list)))\n",
    "\n",
    "                    single_label_f1_0_1_tensor, single_predicted_f1_0_1_tensor = functions.create_0_1_tensor_for_f1(single_sequencial_label, predicted_disease_tokens_list)\n",
    "                    label_f1_0_1_tensor = torch.cat([label_f1_0_1_tensor, single_label_f1_0_1_tensor])\n",
    "                    predicted_f1_0_1_tensor = torch.cat([predicted_f1_0_1_tensor, single_predicted_f1_0_1_tensor])\n",
    "\n",
    "                    \n",
    "                    label_AUROC_tesnor = torch.cat([label_AUROC_tesnor, single_label_AUROC_0_1_tensor.to(device).type(torch.int)])\n",
    "                    predicted_AUROC_tensor = torch.cat([predicted_AUROC_tensor, single_probability_AUROC_predicted])\n",
    "                    if batch_size_transformer*i+j == random_outout_index:\n",
    "                        print('label: ', single_sequencial_label)\n",
    "                        print('predicted: ', predicted_token_list)\n",
    "\n",
    "\n",
    "\n",
    "        label_f1_0_1_tensor = label_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        predicted_f1_0_1_tensor = predicted_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        valid_f1_micro = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='micro', multidim_average='global')\n",
    "        valid_f1_weighted = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='weighted', multidim_average='global')\n",
    "\n",
    "\n",
    "        label_AUROC_tesnor = label_AUROC_tesnor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        predicted_AUROC_tensor = predicted_AUROC_tensor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        valid_AUROC_micro = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='micro')\n",
    "        valid_AUROC_weighted = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='weighted')\n",
    "\n",
    "        valid_precision_micro = torchmetrics.functional.classification.multilabel_precision(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "        valid_recall_micro = torchmetrics.functional.classification.multilabel_recall(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "\n",
    "    return validation_loss/df_validation_top500.shape[0], category_accuracy/df_validation_top500.shape[0], first_class_accuracy/df_validation_top500.shape[0], second_class_accuracy/df_validation_top500.shape[0], disease_accuracy/df_validation_top500.shape[0], valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(train_dataloader, validation_dataloader, epochs=5):\n",
    "\n",
    "    # config = { 'batch_size': batch_size_transformer, 'lr':learning_rate, 'loss':'CrossEntropyLoss', 'optim':'Adam', \n",
    "    #           'transformer_decoder_nhead':transformer_nhead, 'transformer_decoder_layers':decoder_num_layers, 'linear_layer':'768-768-Gelu-768', 'epochs':epochs}\n",
    "    # wandb.init(project=\"htc_mimc3_personal\",entity='ranniu', config=config)\n",
    "\n",
    "    print('Training start...')\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    iter_gradient_accumulation = args.iter_gradient_accumulation\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        loss_training_epoch = 0\n",
    "\n",
    "        transformer_model.train()\n",
    "        for i, (batch_input_ids_tensor, batch_encoder_output_mask, batch_label_index, batch_padding_mask) in tqdm(enumerate(train_dataloader)):\n",
    "            # torch.cuda.empty_cache()\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                loss_training_batch = 0\n",
    "                batch_label_index = batch_label_index.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "                batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "                batch_input_ids_tensor = batch_input_ids_tensor.to(device, non_blocking=True)  # (b,n,128) n is the largest number of sentenses in a sample\n",
    "                batch_encoder_output_mask = batch_encoder_output_mask.to(device, non_blocking=True)  #  (b,n)  n is the largest number of sentenses in a sample\n",
    "                \n",
    "\n",
    "                # attention_mask_train = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)\n",
    "                # masked is True, not masked is False\n",
    "                batch_logits = transformer_model(class_embeddings_dict, mask_dict, batch_input_ids_tensor=batch_input_ids_tensor, batch_label_index=batch_label_index, batch_padding_mask=batch_padding_mask, encoder_output_mask=batch_encoder_output_mask)   # (b,n,768), (b,L) --> (b,L,C)\n",
    "                batch_logits = batch_logits.permute((0,2,1))    # --> (b,C,L)\n",
    "                end_start_index_label = class_label_index_dict['/start'] \n",
    "                lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "                loss_training_batch = criterion(batch_logits, lable_for_loss_tensor)  # (b,C,L), (b,L) --> tensor\n",
    "\n",
    "            \n",
    "            scaler.scale(loss_training_batch).backward()\n",
    "            if (i + 1) % iter_gradient_accumulation == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()         \n",
    "            loss_training_epoch += loss_training_batch.item()\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        print('the training loss in epoch',epoch+1,'is:',loss_training_epoch/df_train_top500.shape[0])\n",
    "        validation_loss, category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy, valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro= valid(validation_dataloader)\n",
    "        # wandb.log({'training_loss': loss_training_epoch/df_train_top500.shape[0]})\n",
    "        # wandb.log({'validation_loss': validation_loss.item()})\n",
    "        # wandb.log({'valid_category_accuracy': category_accuracy})\n",
    "        # wandb.log({'valid_first_class_accuracy': first_class_accuracy})\n",
    "        # wandb.log({'valid_second_class_accuracy': second_class_accuracy})\n",
    "        # wandb.log({'valid_disease_accuracy': disease_accuracy})\n",
    "        # wandb.log({'valid_f1_micro': valid_f1_micro.item()})\n",
    "        # wandb.log({'valid_f1_weighted': valid_f1_weighted.item()})\n",
    "        # wandb.log({'valid_AUROC_micro': valid_AUROC_micro.item()})\n",
    "        # wandb.log({'valid_AUROC_weighted': valid_AUROC_weighted.item()})\n",
    "        # wandb.log({'valid_precision_micro': valid_precision_micro.item()})\n",
    "        # wandb.log({'valid_recall_micro': valid_recall_micro.item()})\n",
    "\n",
    "        print('the valid loss in epoch',epoch+1,'is:', validation_loss.item())\n",
    "        print('the valid accuracy in epoch',epoch+1,'is:', category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy)\n",
    "        print('the valid f1 micro in epoch',epoch+1,'is:', valid_f1_micro.item())\n",
    "        print('the valid f1 weighted in epoch',epoch+1,'is:', valid_f1_weighted.item())\n",
    "        print('the valid AUROC micro in epoch',epoch+1,'is:', valid_AUROC_micro.item())\n",
    "        print('the valid AUROC weighted in epoch',epoch+1,'is:', valid_AUROC_weighted.item())\n",
    "        print('the valid_precision micro in epoch',epoch+1,'is:', valid_precision_micro.item())\n",
    "        print('the valid_recall_micro weighted in epoch',epoch+1,'is:', valid_recall_micro.item())\n",
    "    \n",
    "    print('Training Finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:06,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 1 is: 104.9833459854126\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178it [1:15:12, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  ['start', '390-459', '401-405', '401', '4019', '/401', '/401-405', '420-429', '427', '42731', '/427', '/420-429', '430-438', '434', '43411', '/434', '/430-438', '/390-459', '460-519', '500-508', '507', '5070', '/507', '/500-508', '/460-519', 'V', 'V10-V19', 'V12', 'V1251', '/V12', '/V10-V19', '/V']\n",
      "predicted:  ['140-239', '200-208', '208', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20891', '20801', '20801', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139', '001-139']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "367it [2:34:52, 25.32s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 1 is: 104.1053466796875\n",
      "the valid accuracy in epoch 1 is: 0.0023540164867381854 0.000494680160892695 0.0 0.0\n",
      "the valid f1 micro in epoch 1 is: 0.0\n",
      "the valid f1 weighted in epoch 1 is: 0.0\n",
      "the valid AUROC micro in epoch 1 is: 0.5004725456237793\n",
      "the valid AUROC weighted in epoch 1 is: 0.4886965751647949\n",
      "the valid_precision micro in epoch 1 is: 0.0\n",
      "the valid_recall_micro weighted in epoch 1 is: 0.0\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:06,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 2 is: 104.97630262374878\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "72it [30:44, 25.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 18\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# mp.set_start_method('spawn',force=True)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m train(train_dataloader, validation_dataloader, epochs\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mepoch)\n",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 18\u001b[0m in \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m     loss_training_epoch \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_training_batch\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=169'>170</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthe training loss in epoch\u001b[39m\u001b[39m'\u001b[39m,epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mis:\u001b[39m\u001b[39m'\u001b[39m,loss_training_epoch\u001b[39m/\u001b[39mdf_train_top500\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m--> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=170'>171</a>\u001b[0m validation_loss, category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy, valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro\u001b[39m=\u001b[39m valid(validation_dataloader)\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=171'>172</a>\u001b[0m \u001b[39m# wandb.log({'training_loss': loss_training_epoch/df_train_top500.shape[0]})\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=172'>173</a>\u001b[0m \u001b[39m# wandb.log({'validation_loss': validation_loss.item()})\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=173'>174</a>\u001b[0m \u001b[39m# wandb.log({'valid_category_accuracy': category_accuracy})\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=181'>182</a>\u001b[0m \u001b[39m# wandb.log({'valid_precision_micro': valid_precision_micro.item()})\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39m# wandb.log({'valid_recall_micro': valid_recall_micro.item()})\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthe valid loss in epoch\u001b[39m\u001b[39m'\u001b[39m,epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mis:\u001b[39m\u001b[39m'\u001b[39m, validation_loss\u001b[39m.\u001b[39mitem())\n",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 18\u001b[0m in \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=52'>53</a>\u001b[0m     predicted_token_probabiluty_list, predicted_index_list, predicted_token_list \u001b[39m=\u001b[39m greedy_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39melif\u001b[39;00m args\u001b[39m.\u001b[39mgenerative_strategy \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbeam_search\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m     predicted_token_probabiluty_list, predicted_index_list, predicted_token_list \u001b[39m=\u001b[39m beam_search(class_embeddings_dict_valid, single_input_ids_tensor_valid, class_embeddings_tensor, single_encoder_output_mask)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39m# predicted_index_list = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# predicted_token_list = []\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# predicted_token_probabiluty_list = []\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=70'>71</a>\u001b[0m \u001b[39m#     if len(predicted_token_list) > 114:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39m#         break\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m \u001b[39mif\u001b[39;00m args\u001b[39m.\u001b[39mgenerative_strategy \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgreedy_search\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 18\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m input_token_index_tensor \u001b[39m=\u001b[39m predicted_index\u001b[39m.\u001b[39mreshape((beam_size,\u001b[39m1\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m input_token_index_tensor[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(device)\u001b[39m.\u001b[39mequal(torch\u001b[39m.\u001b[39mtensor([end_start_index_label]\u001b[39m*\u001b[39mbeam_size)\u001b[39m.\u001b[39mto(device)):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m     logits, past_key_values \u001b[39m=\u001b[39m transformer_model\u001b[39m.\u001b[39;49mforward_valid(class_embeddings_dict_valid, mask_dict, class_embeddings_tensor, batch_text_embedding_tensor\u001b[39m=\u001b[39;49mbatch_text_embedding_tensor, batch_label_index\u001b[39m=\u001b[39;49minput_token_index_tensor, encoder_output_mask\u001b[39m=\u001b[39;49msingle_encoder_output_mask, past_key_values\u001b[39m=\u001b[39;49mpast_key_values)   \u001b[39m# (beam,n,768), (beam,L) --> (beam,L,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m     logits \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mSoftmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)(logits[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,:])  \u001b[39m# (beam, C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m     predicted_prob_single \u001b[39m=\u001b[39m logits  \u001b[39m# (beam, C)\u001b[39;00m\n",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 18\u001b[0m in \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=90'>91</a>\u001b[0m \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m batch_label_index:  \u001b[39m# (b,L)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=91'>92</a>\u001b[0m     batch_mask_list\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mstack([mask_dict[index_to_class_label_dict[index\u001b[39m.\u001b[39mitem()]] \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m item]))   \u001b[39m# (L,C)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=92'>93</a>\u001b[0m batch_mask_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mstack(batch_mask_list)   \u001b[39m# (1,L,C)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=93'>94</a>\u001b[0m batch_mask_tensor \u001b[39m=\u001b[39m batch_mask_tensor\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=94'>95</a>\u001b[0m logits \u001b[39m=\u001b[39m (score_tensor\u001b[39m+\u001b[39mbatch_mask_tensor)   \u001b[39m# (1,L,C)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# mp.set_start_method('spawn',force=True)\n",
    "train(train_dataloader, validation_dataloader, epochs=args.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer_model, './trained_model/train02.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2987113b9c300c1ae8cab2be01e277860fb941e8f6dd0f5e5312227dbdee95ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
