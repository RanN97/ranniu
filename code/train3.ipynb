{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/venv_1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchmetrics\n",
    "import ast\n",
    "import random\n",
    "import transformers\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import tree\n",
    "import functions\n",
    "from functions import Dataset_create_embeddings_from_tokens_for_text, Clinical_Bert_Model, Dataset_create_embeddings_from_classdescripsion_for_classsentence_list\n",
    "import sequence_label\n",
    "import wandb\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import multiprocessing as mp\n",
    "import argparse_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse_para.arg_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1391/1391 [00:00<00:00, 57202.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease = tree.build_a_tree()\n",
    "# build the tree, it is four dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b', ignore_mismatched_sizes=True)\n",
    "clinical_DS_bert = transformers.BertModel.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b')\n",
    "# get the pre-trained bert model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device('cpu')\n",
    "print('GPU', torch.cuda.is_available())\n",
    "\n",
    "clinical_Bert_Model = Clinical_Bert_Model(clinical_DS_bert=clinical_DS_bert)\n",
    "clinical_Bert_Model = clinical_Bert_Model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15978/15978 [41:44<00:00,  6.38it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of class_embedding_tensor is:  torch.Size([15978, 768])\n",
      "the length of class embedding is(end tokens not included) 15978\n"
     ]
    }
   ],
   "source": [
    "# this dataframe contains the incd9 classes embeddings\n",
    "\n",
    "df_classes_descripsion = functions.create_classes_descripsions(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# df_classes_descripsion_embeddings has two columns: 'classes' and 'descripsion', and the length of it is all the category and subclass(end tokens not included).\n",
    "\n",
    "class_input_ids_tensor = functions.create_class_bert_tokens(df_classes_descripsion, tokenizer)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "class_input_ids_tensor = class_input_ids_tensor.detach()\n",
    "create_class_embeddings_dataset = Dataset_create_embeddings_from_classdescripsion_for_classsentence_list(class_input_ids_tensor)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "create_class_embeddings_dataloader = DataLoader(create_class_embeddings_dataset, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "class_embeddings_tensor = functions.create_classes_embeddings(create_class_embeddings_dataloader, clinical_Bert_Model, device)\n",
    "print('the shape of class_embedding_tensor is: ', class_embeddings_tensor.shape)\n",
    "class_embeddings_dict = functions.create_class_embeddings_dict(list(df_classes_descripsion['classes']), class_embeddings_tensor)\n",
    "print('the length of class embedding is(end tokens not included)',len(class_embeddings_dict))\n",
    "# keys are classes and values are embeddings tensors, and the length of it is all the category and subclass(end tokens not included).\n",
    "# the shape of embeddings is (n, 768)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(class_embeddings_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_top500 = pd.read_csv('./data/top500_datasets/trainset_top500_new.csv')\n",
    "df_validation_top500 = pd.read_csv('./data/top500_datasets/validationset_top500_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/htc_mimic3/functions.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(\"(Admission Date:)|(Discharge Date:)|(Service:)|(Date of Birth:)|(Sex:)|(Attending:)|(Provider:)|(Name:)|(Date/Time:)|(MD Phone:)|(Completed by:)|(Job#:)|(Dictated By:)|(D: )|(T: )|(JOB :)\", \"\", dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '', dataframe['TEXT'].iloc[i])  # delete [**      **]\n",
      "/u/home/niur/htc_mimic3/functions.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}', '', dataframe['TEXT'].iloc[i])  # delete 12:11\n",
      "/u/home/niur/htc_mimic3/functions.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}AM', '', dataframe['TEXT'].iloc[i])  # delete 12:11AM\n",
      "/u/home/niur/htc_mimic3/functions.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}PM', '', dataframe['TEXT'].iloc[i])  # delete 12:11PM\n",
      "/u/home/niur/htc_mimic3/functions.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('==+', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(' +', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('# *', ' ', dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('\\n.\\n', '\\n\\n', dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = dataframe['TEXT'].iloc[i].split('\\n\\n')\n",
      "/u/home/niur/htc_mimic3/functions.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = temp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HADM_ID', 'TEXT', 'ICD9_CODE', 'SEQUENCIAL_LABEL'], dtype='object')\n",
      "(8286, 4) (1468, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train_top500 = functions.text_cleaning(df_train_top500)\n",
    "df_validation_top500 = functions.text_cleaning(df_validation_top500)\n",
    "df_train_top500 = functions.convert_icdstr_to_list(df_train_top500)\n",
    "df_validation_top500 = functions.convert_icdstr_to_list(df_validation_top500)\n",
    "df_train_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_train_top500)\n",
    "df_validation_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_validation_top500)\n",
    "print(df_train_top500.columns)\n",
    "print(df_train_top500.shape, df_validation_top500.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8286/8286 [04:25<00:00, 31.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train token shape: 8286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1468/1468 [00:45<00:00, 32.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid token shape: 1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ids_list_train = functions.create_text_tokens(df_train_top500, tokenizer) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "# input_ids_list_train = input_ids_list_train.detach()\n",
    "print('train token shape:', len(input_ids_list_train))\n",
    "input_ids_list_validation = functions.create_text_tokens(df_validation_top500, tokenizer) # , token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "# input_ids_list_validation = input_ids_list_validation.detach()\n",
    "print('valid token shape:', len(input_ids_list_validation))\n",
    "\n",
    "# train_dataset_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_train) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "# validation_datasdet_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_validation) #, token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "# train_dataloader_top500_create_text_embeddings = DataLoader(train_dataset_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "# validation_dataloader_top500_create_text_embeddings = DataLoader(validation_datasdet_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "\n",
    "\n",
    "# train_text_embeddings_tensor = functions.create_text_embeddings(train_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# validation_text_embeddings_tensor = functions.create_text_embeddings(validation_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# # this is the outputs of encoder and will be the cross attention input of decoder.\n",
    "# print('train text embedding shape:', train_text_embeddings_tensor.shape)\n",
    "# print('valid text embedding shape:', validation_text_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of mask dict is: 17392\n"
     ]
    }
   ],
   "source": [
    "mask_dict = functions.create_tokens_mask_dict(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# it s a dictionary contains the -inf and 0 mask(1d tensor) of each category and subclass.\n",
    "class_label_index_dict = functions.create_class_label_index_dict(mask_dict)\n",
    "# {'start':0, .......}\n",
    "index_to_class_label_dict = functions.create_index_to_class_label_dict(mask_dict)\n",
    "# {0:'start', .......}\n",
    "print('the length of mask dict is:',len(class_label_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequencial_label_list = list(df_train_top500['SEQUENCIAL_LABEL'])       # [[L], [L], [L]......]\n",
    "valiation_sequencial_label_list = list(df_validation_top500['SEQUENCIAL_LABEL'])\n",
    "# here the data pass into the dataset can not be tensors, because change into embeddings need the complete class embedding dict.\n",
    "\n",
    "train_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, train_sequencial_label_list)  # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "validation_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, valiation_sequencial_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_transformer(Dataset):\n",
    "    def __init__(self, input_ids_list_train, label_index_list):\n",
    "        self.input_ids_list_train = input_ids_list_train   #[(n,128), (n,128), (n,128), (n,128), (n,128), (n,128), (n,128)]\n",
    "        self.label_index_list = label_index_list      # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids_list_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids_list_train[index], self.label_index_list[index]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    batch_input_ids_list = [item[0] for item in batch]  #[(n,128), (n,128), (n,128), (n,128), (n,128), (n,128), (n,128)]\n",
    "    batch_input_ids_tensor = torch.nn.utils.rnn.pad_sequence(batch_input_ids_list, batch_first=True)  # (b,n,128)  n is the largest number of sentences in a samples batch.\n",
    "    encoder_output_mask = []\n",
    "    for item in batch_input_ids_list:\n",
    "        single_mask = torch.tensor([True]*batch_input_ids_tensor.shape[1])  # masked is True\n",
    "        single_mask[:item.shape[0]] = False    # not masked is False\n",
    "        encoder_output_mask.append(single_mask)\n",
    "    encoder_output_mask = torch.stack(encoder_output_mask) # (b,n)\n",
    "    \n",
    "    \n",
    "    batch_label_index = torch.nn.utils.rnn.pad_sequence([item[1] for item in batch], batch_first=True, padding_value=17391)  # (b,L) L is the largest length in this batch\n",
    "    max_L = batch_label_index.shape[1]\n",
    "    padding_mask = []\n",
    "    for item in batch:\n",
    "        single_mask = torch.tensor([float('-inf')]*max_L)  # masked is True\n",
    "        true_L = item[1].shape[0]\n",
    "        single_mask[:true_L] = 0.0    # not masked is False\n",
    "        padding_mask.append(single_mask)\n",
    "    padding_mask = torch.stack(padding_mask)   # (b,L) L is the largest length in this batch   (0,-inf)\n",
    "\n",
    "    \n",
    "    return batch_input_ids_tensor, encoder_output_mask, batch_label_index, padding_mask     #  (b,n,128) (b,n) (b,L) (b,L)  L is the largest length in this batch \n",
    "\n",
    "\n",
    "train_dataset = Dataset_transformer(input_ids_list_train, train_label_index_list)\n",
    "validation_dataset = Dataset_transformer(input_ids_list_validation, validation_label_index_list)\n",
    "batch_size_transformer = args.batch_size_transformer\n",
    "num_workers = args.num_workers\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size_transformer, shuffle=True, drop_last=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)  \n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=batch_size_transformer, shuffle=False, drop_last=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
    "decoder_num_layers = args.decoder_num_layers\n",
    "transformer_dropout = args.transformer_dropout\n",
    "transformer_nhead = args.transformer_nhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer_Model, self).__init__()\n",
    "\n",
    "        self.clinical_bert = clinical_DS_bert\n",
    "        for lay in self.clinical_bert.encoder.layer[args.bert_freeze_layerindex_start:args.bert_freeze_layerindex_end+1]:\n",
    "            for para in lay.parameters():\n",
    "                para.requires_grad = False\n",
    "\n",
    "        self.class_embeddings_start = torch.nn.Parameter(torch.randn(768))\n",
    "        self.class_embeddings_end_start = torch.nn.Parameter(torch.randn(768))\n",
    "\n",
    "        self.decoder_layer = torch.nn.TransformerDecoderLayer(d_model=768, nhead=transformer_nhead, dropout=transformer_dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(self.decoder_layer, num_layers=decoder_num_layers)  # forward padding mask(N,L)  attention causal mask(L,L)  multiheadattention  is_causal\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.linear2 = torch.nn.Linear(768, 768)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, class_embeddings_dict, mask_dict, batch_input_ids_tensor, batch_label_index, attention_mask, batch_padding_mask, encoder_output_mask):   #  (b,n,128), (b,L)  (b,L)  (b,n)\n",
    "\n",
    "        class_embeddings_dict = functions.add_end_classes_embeddings(class_embeddings_dict, self.class_embeddings_start, self.class_embeddings_end_start, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, device)\n",
    "        class_embedding_list = []\n",
    "        for item in list(mask_dict.keys())[:-1]:\n",
    "            class_embedding_list.append(class_embeddings_dict[item])\n",
    "        class_embeddings_tensor = torch.stack(class_embedding_list)    # (C,768) C:17391\n",
    "\n",
    "        label_embedding_tensor = functions.convert_sequencial_label_to_embedding_tensor(batch_label_index, class_embeddings_dict, index_to_class_label_dict)  # (b,L) --> (b,L,768)\n",
    "        \n",
    "        batch_text_embedding_tensor = torch.stack([self.clinical_bert(single_input_ids_tensor)['last_hidden_state'][:,0,:] for single_input_ids_tensor in batch_input_ids_tensor])   # (b,n,768)\n",
    "        decoder_output = self.transformer_decoder(label_embedding_tensor, batch_text_embedding_tensor, tgt_mask=attention_mask, tgt_key_padding_mask=batch_padding_mask, memory_key_padding_mask=encoder_output_mask)#  (b,L,768)  (b,n,768) -->  (b,L,768)\n",
    "\n",
    "        transformer_output = self.linear1(decoder_output)   #  (b,L,768)\n",
    "        transformer_output = self.gelu(transformer_output)\n",
    "        transformer_output = self.linear2(transformer_output)  #  (b,L,768)\n",
    "\n",
    "        transformer_output = torch.nn.functional.normalize(transformer_output, dim=-1)  # (b,L,768)\n",
    "        class_embeddings_tensor = torch.nn.functional.normalize(class_embeddings_tensor, dim=-1)  #  (C,768)\n",
    "\n",
    "        # score_tensor = torch.nn.functional.cosine_similarity(transformer_output.unsqueeze(0).permute((1,0,2)), class_embeddings_tensor.unsqueeze(0), dim=-1)  # (L,1,768) (1,C,768) --> (L,C)\n",
    "        score_tensor = torch.matmul(transformer_output, class_embeddings_tensor.T).to(dtype=torch.float16)  # (b,L,768), (768,C)  -->  (b,L,C)\n",
    "        batch_mask_list = []\n",
    "        for item in batch_label_index:  # (b,L)\n",
    "            batch_mask_list.append(torch.stack([mask_dict[index_to_class_label_dict[index.item()]] for index in item]))   # (L,C)\n",
    "        batch_mask_tensor = torch.stack(batch_mask_list)   # (b,L,C)\n",
    "        batch_mask_tensor = batch_mask_tensor.to(device)\n",
    "        logits = (score_tensor+batch_mask_tensor)   # (b,L,C)\n",
    "        return logits  # (b,L,C)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = Transformer_Model()\n",
    "transformer_model = transformer_model.to(device)\n",
    "learning_rate = args.learning_rate\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum', ignore_index=17391)    # when compute, the size must be (N, C, L) and (N, L)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=learning_rate, weight_decay=args.adam_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(validation_dataloader):\n",
    "    transformer_model.eval()\n",
    "    print('Validation start...')\n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        category_accuracy = 0\n",
    "        first_class_accuracy = 0\n",
    "        second_class_accuracy = 0\n",
    "        disease_accuracy = 0\n",
    "        label_f1_0_1_tensor = torch.tensor([])\n",
    "        predicted_f1_0_1_tensor = torch.tensor([])\n",
    "        label_AUROC_tesnor = torch.tensor([],dtype=int).to(device)\n",
    "        predicted_AUROC_tensor = torch.tensor([]).to(device)\n",
    "        random_outout_index = random.randint(0,1000)\n",
    "        for i, (batch_input_ids_tensor, batch_encoder_output_mask, batch_label_index, batch_padding_mask) in tqdm(enumerate(validation_dataloader)):\n",
    "\n",
    "            # torch.cuda.empty_cache()\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                batch_input_ids_tensor = batch_input_ids_tensor.to(device, non_blocking=True)\n",
    "                batch_label_index = batch_label_index.to(device, non_blocking=True)\n",
    "                batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)\n",
    "                batch_encoder_output_mask = batch_encoder_output_mask.to(device, non_blocking=True)\n",
    "                attention_mask_valid = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)   # masked is True, not masked is False\n",
    "                \n",
    "\n",
    "                batch_logits = transformer_model(class_embeddings_dict, mask_dict, batch_input_ids_tensor=batch_input_ids_tensor, batch_label_index=batch_label_index, attention_mask=attention_mask_valid, batch_padding_mask=batch_padding_mask, encoder_output_mask=batch_encoder_output_mask)   # (b,n,128), (b,L) --> (b,L,C)\n",
    "                batch_logits = batch_logits.permute((0,2,1))   # --> (b,C,L)\n",
    "                end_start_index_label = class_label_index_dict['/start'] \n",
    "                lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "                validation_loss += criterion(batch_logits, lable_for_loss_tensor)\n",
    "\n",
    "                for j in range(batch_input_ids_tensor.shape[0]):\n",
    "                    \n",
    "                    single_input_ids_tensor_valid = batch_input_ids_tensor[j].unsqueeze(0)   # (1,n,128)\n",
    "                    single_encoder_output_mask = batch_encoder_output_mask[j].unsqueeze(0)  # (1,n)\n",
    "\n",
    "                    single_label_index_list = batch_label_index[j].tolist()    # [L]\n",
    "                    padding_index = single_label_index_list.index(17391) if 17391 in single_label_index_list else len(single_label_index_list)\n",
    "                    single_label_index_list = single_label_index_list[:padding_index]\n",
    "                    single_sequencial_label = [index_to_class_label_dict[index] for index in single_label_index_list]\n",
    "\n",
    "                    # ingle_label_index_tensor = label_index_list[j].unsqueeze(0)    # (1,L)\n",
    "                    # single_text_embedding_tensor = single_text_embedding_tensor.to(device)\n",
    "                    # single_label_index_tensor = single_label_index_tensor.to(device)\n",
    "\n",
    "                    predicted_index_list = []\n",
    "                    predicted_token_list = []\n",
    "                    predicted_token_probabiluty_list = []\n",
    "                    input_token_index_list = [class_label_index_dict['start']]\n",
    "                    end_start_index_label = class_label_index_dict['/start'] \n",
    "                    while input_token_index_list[-1] != end_start_index_label:\n",
    "                        logits = transformer_model(class_embeddings_dict, mask_dict, batch_input_ids_tensor=single_input_ids_tensor_valid, batch_label_index=torch.tensor([input_token_index_list]).to(device, non_blocking=True), attention_mask=None, batch_padding_mask=None, encoder_output_mask=single_encoder_output_mask)   # (1,n,128), (1,L) --> (1,L,C)\n",
    "                        predicted_index = torch.argmax(logits.squeeze(0), dim=-1)[-1].item()   # (1,L,C)-->int\n",
    "                        predicted_token_probabiluty_list.append(logits.squeeze(0)[-1])  # (1,L,C) -->[L,(C)]\n",
    "                        predicted_index_list.append(predicted_index)   # [L]\n",
    "                        predicted_token_list.append(index_to_class_label_dict[predicted_index])  # [L]\n",
    "                        input_token_index_list.append(predicted_index)   # [L]\n",
    "\n",
    "                        if len(predicted_token_list) > 150:\n",
    "                            break\n",
    "\n",
    "                    predicted_token_probabiluty_tensor = torch.nn.Softmax(dim=-1)(torch.stack(predicted_token_probabiluty_list))  # (L,C)\n",
    "                    predicted_category_tokens_list, predicted_first_class_tokens_list, predicted_second_class_tokens_list, predicted_disease_tokens_list = functions.split_predicted_class_tokens(predicted_token_list, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                    label_category_tokens_list, label_first_class_tokens_list, label_second_class_tokens_list, label_disease_tokens_list = functions.split_predicted_class_tokens(single_sequencial_label, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                    category_accuracy += (len(set(predicted_category_tokens_list).intersection(set(label_category_tokens_list))) / max(len(predicted_category_tokens_list), len(label_category_tokens_list)))\n",
    "                    first_class_accuracy += (len(set(predicted_first_class_tokens_list).intersection(set(label_first_class_tokens_list))) / max(len(predicted_first_class_tokens_list), len(label_first_class_tokens_list)))\n",
    "                    second_class_accuracy += (len(set(predicted_second_class_tokens_list).intersection(set(label_second_class_tokens_list))) / max(len(predicted_second_class_tokens_list), len(label_second_class_tokens_list)))\n",
    "                    disease_accuracy += (len(set(predicted_disease_tokens_list).intersection(set(label_disease_tokens_list))) / max(len(predicted_disease_tokens_list), len(label_disease_tokens_list)))\n",
    "\n",
    "                    single_label_f1_0_1_tensor, single_predicted_f1_0_1_tensor = functions.create_0_1_tensor_for_f1(single_sequencial_label, predicted_disease_tokens_list)\n",
    "                    label_f1_0_1_tensor = torch.cat([label_f1_0_1_tensor, single_label_f1_0_1_tensor])\n",
    "                    predicted_f1_0_1_tensor = torch.cat([predicted_f1_0_1_tensor, single_predicted_f1_0_1_tensor])\n",
    "\n",
    "                    single_probability_AUROC_predicted, single_label_AUROC_0_1_tensor = functions.create_probability_tensor_for_AUROC(single_sequencial_label, class_label_index_dict, predicted_token_probabiluty_tensor, predicted_index_list, device)\n",
    "                    label_AUROC_tesnor = torch.cat([label_AUROC_tesnor, single_label_AUROC_0_1_tensor.to(device).type(torch.int)])\n",
    "                    predicted_AUROC_tensor = torch.cat([predicted_AUROC_tensor, single_probability_AUROC_predicted])\n",
    "\n",
    "                    if batch_size_transformer*i+j == random_outout_index:\n",
    "                        print('label: ', single_sequencial_label)\n",
    "                        print('predicted: ', predicted_token_list)\n",
    "\n",
    "\n",
    "\n",
    "        label_f1_0_1_tensor = label_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        predicted_f1_0_1_tensor = predicted_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        valid_f1_micro = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='micro', multidim_average='global')\n",
    "        valid_f1_weighted = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='weighted', multidim_average='global')\n",
    "\n",
    "\n",
    "        label_AUROC_tesnor = label_AUROC_tesnor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        predicted_AUROC_tensor = predicted_AUROC_tensor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        valid_AUROC_micro = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='micro')\n",
    "        valid_AUROC_weighted = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='weighted')\n",
    "\n",
    "        valid_precision_micro = torchmetrics.functional.classification.multilabel_precision(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "        valid_recall_micro = torchmetrics.functional.classification.multilabel_recall(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "\n",
    "    return validation_loss/df_validation_top500.shape[0], category_accuracy/df_validation_top500.shape[0], first_class_accuracy/df_validation_top500.shape[0], second_class_accuracy/df_validation_top500.shape[0], disease_accuracy/df_validation_top500.shape[0], valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(train_dataloader, validation_dataloader, epochs=5):\n",
    "\n",
    "    # config = { 'batch_size': batch_size_transformer, 'lr':learning_rate, 'loss':'CrossEntropyLoss', 'optim':'Adam', \n",
    "    #           'transformer_decoder_nhead':transformer_nhead, 'transformer_decoder_layers':decoder_num_layers, 'linear_layer':'768-768-Gelu-768', 'epochs':epochs}\n",
    "    # wandb.init(project=\"Result\", entity=\"htc-mimic3\", config=config)\n",
    "\n",
    "    print('Training start...')\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    iter_gradient_accumulation = args.iter_gradient_accumulation\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        loss_training_epoch = 0\n",
    "\n",
    "        transformer_model.train()\n",
    "        for i, (batch_input_ids_tensor, batch_encoder_output_mask, batch_label_index, batch_padding_mask) in tqdm(enumerate(train_dataloader)):\n",
    "            # torch.cuda.empty_cache()\n",
    "            with torch.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                loss_training_batch = 0\n",
    "                batch_label_index = batch_label_index.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "                batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "                batch_input_ids_tensor = batch_input_ids_tensor.to(device, non_blocking=True)  # (b,n,128) n is the largest number of sentenses in a sample\n",
    "                batch_encoder_output_mask = batch_encoder_output_mask.to(device, non_blocking=True)  #  (b,n)  n is the largest number of sentenses in a sample\n",
    "                \n",
    "\n",
    "                attention_mask_train = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)\n",
    "                # masked is True, not masked is False\n",
    "                batch_logits = transformer_model(class_embeddings_dict, mask_dict, batch_input_ids_tensor=batch_input_ids_tensor, batch_label_index=batch_label_index, attention_mask=attention_mask_train, batch_padding_mask=batch_padding_mask, encoder_output_mask=batch_encoder_output_mask)   # (b,4,768), (b,L) --> (b,L,C)\n",
    "                batch_logits = batch_logits.permute((0,2,1))    # --> (b,C,L)\n",
    "                end_start_index_label = class_label_index_dict['/start'] \n",
    "                lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "                loss_training_batch = criterion(batch_logits, lable_for_loss_tensor)  # (b,C,L), (b,L) --> tensor\n",
    "\n",
    "            \n",
    "            scaler.scale(loss_training_batch).backward()\n",
    "            if (i + 1) % iter_gradient_accumulation == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()         \n",
    "            loss_training_epoch += loss_training_batch.item()\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        print('the training loss in epoch',epoch+1,'is:',loss_training_epoch/df_train_top500.shape[0])\n",
    "        validation_loss, category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy, valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro= valid(validation_dataloader)\n",
    "        # wandb.log({'training_loss': loss_training_epoch/df_train_top500.shape[0]})\n",
    "        # wandb.log({'validation_loss': validation_loss.item()})\n",
    "        # wandb.log({'valid_category_accuracy': category_accuracy})\n",
    "        # wandb.log({'valid_first_class_accuracy': first_class_accuracy})\n",
    "        # wandb.log({'valid_second_class_accuracy': second_class_accuracy})\n",
    "        # wandb.log({'valid_disease_accuracy': disease_accuracy})\n",
    "        # wandb.log({'valid_f1_micro': valid_f1_micro.item()})\n",
    "        # wandb.log({'valid_f1_weighted': valid_f1_weighted.item()})\n",
    "        # wandb.log({'valid_AUROC_micro': valid_AUROC_micro.item()})\n",
    "        # wandb.log({'valid_AUROC_weighted': valid_AUROC_weighted.item()})\n",
    "        # wandb.log({'valid_precision_micro': valid_precision_micro.item()})\n",
    "        # wandb.log({'valid_recall_micro': valid_recall_micro.item()})\n",
    "\n",
    "        print('the valid loss in epoch',epoch+1,'is:', validation_loss.item())\n",
    "        print('the valid accuracy in epoch',epoch+1,'is:', category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy)\n",
    "        print('the valid f1 micro in epoch',epoch+1,'is:', valid_f1_micro.item())\n",
    "        print('the valid f1 weighted in epoch',epoch+1,'is:', valid_f1_weighted.item())\n",
    "        print('the valid AUROC micro in epoch',epoch+1,'is:', valid_AUROC_micro.item())\n",
    "        print('the valid AUROC weighted in epoch',epoch+1,'is:', valid_AUROC_weighted.item())\n",
    "        print('the valid_precision micro in epoch',epoch+1,'is:', valid_precision_micro.item())\n",
    "        print('the valid_recall_micro weighted in epoch',epoch+1,'is:', valid_recall_micro.item())\n",
    "    \n",
    "    print('Training Finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp.set_start_method('spawn',force=True)\n",
    "train(train_dataloader, validation_dataloader, epochs=args.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(transformer_model, './trained_model/train02.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click  argparse\n",
    "# mix precision  √\n",
    "# gradient accumulation  √\n",
    "# gpt2 \n",
    "# freeze bert  √\n",
    "# generation in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation : which maks was used?\n",
    "# gradient accumulation and mix precision right?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2987113b9c300c1ae8cab2be01e277860fb941e8f6dd0f5e5312227dbdee95ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
