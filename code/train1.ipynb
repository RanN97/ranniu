{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/venv_1/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torchmetrics\n",
    "import ast\n",
    "import random\n",
    "import transformers\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import tree\n",
    "import functions\n",
    "from functions import Dataset_create_embeddings_from_tokens_for_text, Clinical_Bert_Model, Dataset_create_embeddings_from_classdescripsion_for_classsentence_list\n",
    "import sequence_label\n",
    "import wandb\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "import multiprocessing as mp\n",
    "import argparse_para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse_para.arg_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1391/1391 [00:00<00:00, 74420.59it/s]\n"
     ]
    }
   ],
   "source": [
    "tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease = tree.build_a_tree()\n",
    "# build the tree, it is four dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b', ignore_mismatched_sizes=True)\n",
    "clinical_DS_bert = transformers.BertModel.from_pretrained('./Model_Bio_Clinical_DS_BERT/Bio_DischargeSummary_BERT/hub/models--emilyalsentzer--Bio_Discharge_Summary_BERT/snapshots/affde836a50e4d333f15dae9270f5a856d59540b')\n",
    "# get the pre-trained bert model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU True\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('GPU', torch.cuda.is_available())\n",
    "\n",
    "clinical_Bert_Model = Clinical_Bert_Model(clinical_DS_bert=clinical_DS_bert)\n",
    "clinical_Bert_Model = clinical_Bert_Model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1683/15978 [00:17<02:27, 97.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/u/home/niur/htc_mimic3/train.ipynb Cell 6\u001b[0m in \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m create_class_embeddings_dataset \u001b[39m=\u001b[39m Dataset_create_embeddings_from_classdescripsion_for_classsentence_list(class_input_ids_tensor)  \u001b[39m# , class_token_type_idstensor, class_attention_mask_tensor\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m create_class_embeddings_dataloader \u001b[39m=\u001b[39m DataLoader(create_class_embeddings_dataset, \u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, drop_last\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m class_embeddings_tensor \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39;49mcreate_classes_embeddings(create_class_embeddings_dataloader, clinical_Bert_Model, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mthe shape of class_embedding_tensor is: \u001b[39m\u001b[39m'\u001b[39m, class_embeddings_tensor\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Balpaca.aim.cit.tum.de/u/home/niur/htc_mimic3/train.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m class_embeddings_dict \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39mcreate_class_embeddings_dict(\u001b[39mlist\u001b[39m(df_classes_descripsion[\u001b[39m'\u001b[39m\u001b[39mclasses\u001b[39m\u001b[39m'\u001b[39m]), class_embeddings_tensor)\n",
      "File \u001b[0;32m~/htc_mimic3/functions.py:308\u001b[0m, in \u001b[0;36mcreate_classes_embeddings\u001b[0;34m(dataloader, clinical_DS_bert_model, device)\u001b[0m\n\u001b[1;32m    305\u001b[0m input_ids_tensor \u001b[39m=\u001b[39m input_ids_tensor\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m,\u001b[39m128\u001b[39m))\n\u001b[1;32m    306\u001b[0m \u001b[39m# token_type_ids_tensor = token_type_ids_tensor.reshape((1,128))\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# attention_mask_tensor = attention_mask_tensor.reshape((1,128))\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m bert_outputs \u001b[39m=\u001b[39m clinical_DS_bert_model(input_ids_tensor)   \u001b[39m# , token_type_ids_tensor, attention_mask_tensor\u001b[39;00m\n\u001b[1;32m    310\u001b[0m embeddings_list\u001b[39m.\u001b[39mappend(bert_outputs)\n\u001b[1;32m    311\u001b[0m embeddings_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(embeddings_list, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/htc_mimic3/functions.py:271\u001b[0m, in \u001b[0;36mClinical_Bert_Model.forward\u001b[0;34m(self, input_ids_tensor)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, input_ids_tensor):   \u001b[39m# , token_type_ids_tensor, attention_mask_tensor\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     bert_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclinical_DS_bert(input_ids_tensor)[\u001b[39m'\u001b[39m\u001b[39mlast_hidden_state\u001b[39m\u001b[39m'\u001b[39m][:,\u001b[39m0\u001b[39m,:]    \u001b[39m# , token_type_ids_tensor, attention_mask_tensor\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m bert_outputs\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:1014\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1005\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1007\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1008\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1009\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1013\u001b[0m )\n\u001b[0;32m-> 1014\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1015\u001b[0m     embedding_output,\n\u001b[1;32m   1016\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1017\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1018\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1019\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1020\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1021\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1022\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1023\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1024\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1025\u001b[0m )\n\u001b[1;32m   1026\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1027\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:603\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    594\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    595\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    596\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    600\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    602\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 603\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    604\u001b[0m         hidden_states,\n\u001b[1;32m    605\u001b[0m         attention_mask,\n\u001b[1;32m    606\u001b[0m         layer_head_mask,\n\u001b[1;32m    607\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    608\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    609\u001b[0m         past_key_value,\n\u001b[1;32m    610\u001b[0m         output_attentions,\n\u001b[1;32m    611\u001b[0m     )\n\u001b[1;32m    613\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    614\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:489\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    478\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    479\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[1;32m    487\u001b[0m     \u001b[39m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    488\u001b[0m     self_attn_past_key_value \u001b[39m=\u001b[39m past_key_value[:\u001b[39m2\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m     self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    490\u001b[0m         hidden_states,\n\u001b[1;32m    491\u001b[0m         attention_mask,\n\u001b[1;32m    492\u001b[0m         head_mask,\n\u001b[1;32m    493\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    494\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    495\u001b[0m     )\n\u001b[1;32m    496\u001b[0m     attention_output \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    498\u001b[0m     \u001b[39m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:419\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    410\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    411\u001b[0m     hidden_states: torch\u001b[39m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m     output_attentions: Optional[\u001b[39mbool\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    418\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[torch\u001b[39m.\u001b[39mTensor]:\n\u001b[0;32m--> 419\u001b[0m     self_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself(\n\u001b[1;32m    420\u001b[0m         hidden_states,\n\u001b[1;32m    421\u001b[0m         attention_mask,\n\u001b[1;32m    422\u001b[0m         head_mask,\n\u001b[1;32m    423\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    424\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    425\u001b[0m         past_key_value,\n\u001b[1;32m    426\u001b[0m         output_attentions,\n\u001b[1;32m    427\u001b[0m     )\n\u001b[1;32m    428\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(self_outputs[\u001b[39m0\u001b[39m], hidden_states)\n\u001b[1;32m    429\u001b[0m     outputs \u001b[39m=\u001b[39m (attention_output,) \u001b[39m+\u001b[39m self_outputs[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/venv_1/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:323\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    320\u001b[0m     past_key_value \u001b[39m=\u001b[39m (key_layer, value_layer)\n\u001b[1;32m    322\u001b[0m \u001b[39m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[39;00m\n\u001b[0;32m--> 323\u001b[0m attention_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(query_layer, key_layer\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m))\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mposition_embedding_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrelative_key_query\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    326\u001b[0m     seq_length \u001b[39m=\u001b[39m hidden_states\u001b[39m.\u001b[39msize()[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this dataframe contains the incd9 classes embeddings\n",
    "\n",
    "df_classes_descripsion = functions.create_classes_descripsions(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# df_classes_descripsion_embeddings has two columns: 'classes' and 'descripsion', and the length of it is all the category and subclass(end tokens not included).\n",
    "\n",
    "class_input_ids_tensor = functions.create_class_bert_tokens(df_classes_descripsion, tokenizer)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "class_input_ids_tensor = class_input_ids_tensor.detach()\n",
    "create_class_embeddings_dataset = Dataset_create_embeddings_from_classdescripsion_for_classsentence_list(class_input_ids_tensor)  # , class_token_type_idstensor, class_attention_mask_tensor\n",
    "create_class_embeddings_dataloader = DataLoader(create_class_embeddings_dataset, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "class_embeddings_tensor = functions.create_classes_embeddings(create_class_embeddings_dataloader, clinical_Bert_Model, device)\n",
    "print('the shape of class_embedding_tensor is: ', class_embeddings_tensor.shape)\n",
    "class_embeddings_dict = functions.create_class_embeddings_dict(list(df_classes_descripsion['classes']), class_embeddings_tensor)\n",
    "print('the length of class embedding is(end tokens not included)',len(class_embeddings_dict))\n",
    "# keys are classes and values are embeddings tensors, and the length of it is all the category and subclass(end tokens not included).\n",
    "# the shape of embeddings is (n, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_top500 = pd.read_csv('./data/top500_datasets/trainset_top500_new.csv')\n",
    "df_validation_top500 = pd.read_csv('./data/top500_datasets/validationset_top500_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/home/niur/htc_mimic3/functions.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(\"(Admission Date:)|(Discharge Date:)|(Service:)|(Date of Birth:)|(Sex:)|(Attending:)|(Provider:)|(Name:)|(Date/Time:)|(MD Phone:)|(Completed by:)|(Job#:)|(Dictated By:)\", \"\", dataframe['TEXT'].iloc[i])\n",
      "/u/home/niur/htc_mimic3/functions.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(r'\\[\\*\\*.*?\\*\\*\\]', '', dataframe['TEXT'].iloc[i])  # delete [**      **]\n",
      "/u/home/niur/htc_mimic3/functions.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}', '', dataframe['TEXT'].iloc[i])  # delete 12:11\n",
      "/u/home/niur/htc_mimic3/functions.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}AM', '', dataframe['TEXT'].iloc[i])  # delete 12:11AM\n",
      "/u/home/niur/htc_mimic3/functions.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('[0-9]{2}:[0-9]{2}PM', '', dataframe['TEXT'].iloc[i])  # delete 12:11PM\n",
      "/u/home/niur/htc_mimic3/functions.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('==+', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub(' +', ' ', dataframe['TEXT'].iloc[i])   # delete redundant space ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('\\n', ' ', dataframe['TEXT'].iloc[i]) # change \\n to ' '\n",
      "/u/home/niur/htc_mimic3/functions.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataframe['TEXT'].iloc[i] = re.sub('# *', ' ', dataframe['TEXT'].iloc[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['HADM_ID', 'TEXT', 'ICD9_CODE', 'SEQUENCIAL_LABEL'], dtype='object')\n",
      "(8496, 4) (1500, 4)\n"
     ]
    }
   ],
   "source": [
    "df_train_top500 = functions.text_cleaning(df_train_top500)\n",
    "df_validation_top500 = functions.text_cleaning(df_validation_top500)\n",
    "df_train_top500 = functions.convert_icdstr_to_list(df_train_top500)\n",
    "df_validation_top500 = functions.convert_icdstr_to_list(df_validation_top500)\n",
    "df_train_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_train_top500)\n",
    "df_validation_top500 = sequence_label.create_sequence_label_depth_first(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, df_validation_top500)\n",
    "print(df_train_top500.columns)\n",
    "print(df_train_top500.shape, df_validation_top500.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8496/8496 [02:31<00:00, 55.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train token shape: torch.Size([8496, 4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:26<00:00, 55.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid token shape: torch.Size([1500, 4, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_ids_tensor_train = functions.create_text_tokens(df_train_top500, tokenizer) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "input_ids_tensor_train = input_ids_tensor_train.detach()\n",
    "print('train token shape:', input_ids_tensor_train.shape)\n",
    "input_ids_tensor_validation = functions.create_text_tokens(df_validation_top500, tokenizer) # , token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "input_ids_tensor_validation = input_ids_tensor_validation.detach()\n",
    "print('valid token shape:', input_ids_tensor_validation.shape)\n",
    "\n",
    "# train_dataset_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_train) # , token_type_idstensor_train, attention_mask_tensor_train\n",
    "# validation_datasdet_top500_create_text_embeddings = Dataset_create_embeddings_from_tokens_for_text(input_ids_tensor_validation) #, token_type_idstensor_validation, attention_mask_tensor_validation\n",
    "# train_dataloader_top500_create_text_embeddings = DataLoader(train_dataset_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "# validation_dataloader_top500_create_text_embeddings = DataLoader(validation_datasdet_top500_create_text_embeddings, 1, shuffle=False, drop_last=False, num_workers=8)\n",
    "\n",
    "\n",
    "# train_text_embeddings_tensor = functions.create_text_embeddings(train_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# validation_text_embeddings_tensor = functions.create_text_embeddings(validation_dataloader_top500_create_text_embeddings, clinical_Bert_Model, device)\n",
    "# # this is the outputs of encoder and will be the cross attention input of decoder.\n",
    "# print('train text embedding shape:', train_text_embeddings_tensor.shape)\n",
    "# print('valid text embedding shape:', validation_text_embeddings_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the length of mask dict is: 17392\n"
     ]
    }
   ],
   "source": [
    "mask_dict = functions.create_tokens_mask_dict(tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "# it s a dictionary contains the -inf and 0 mask(1d tensor) of each category and subclass.\n",
    "class_label_index_dict = functions.create_class_label_index_dict(mask_dict)\n",
    "# {'start':0, .......}\n",
    "index_to_class_label_dict = functions.create_index_to_class_label_dict(mask_dict)\n",
    "# {0:'start', .......}\n",
    "print('the length of mask dict is:',len(class_label_index_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequencial_label_list = list(df_train_top500['SEQUENCIAL_LABEL'])       # [[L], [L], [L]......]\n",
    "valiation_sequencial_label_list = list(df_validation_top500['SEQUENCIAL_LABEL'])\n",
    "# here the data pass into the dataset can not be tensors, because change into embeddings need the complete class embedding dict.\n",
    "\n",
    "train_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, train_sequencial_label_list)  # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "validation_label_index_list = functions.convrt_sequencial_label_to_label_index(class_label_index_dict, valiation_sequencial_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset_transformer(Dataset):\n",
    "    def __init__(self, input_ids_tensor_train, label_index_list):\n",
    "        self.input_ids_tensor_train = input_ids_tensor_train   #(N, 4, 512)\n",
    "        self.label_index_list = label_index_list      # [tensor(L), tensor(L), tensor(L), tensor(L), tensor(L).......]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.input_ids_tensor_train.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.input_ids_tensor_train[index], self.label_index_list[index]\n",
    "    \n",
    "def collate_fn(batch):\n",
    "    input_ids_tensor_train = torch.stack([item[0] for item in batch])   # (b,4,512)\n",
    "    batch_label_index = torch.nn.utils.rnn.pad_sequence([item[1] for item in batch], batch_first=True, padding_value=17391)  # (b,L) L is the largest length in this batch\n",
    "    max_L = batch_label_index.shape[1]\n",
    "    padding_mask = []\n",
    "    for item in batch:\n",
    "        single_mask = torch.tensor([float('-inf')]*max_L)  # masked is True\n",
    "        true_L = item[1].shape[0]\n",
    "        single_mask[:true_L] = 0.0    # not masked is False\n",
    "        padding_mask.append(single_mask)\n",
    "    padding_mask = torch.stack(padding_mask)   # (b,L) L is the largest length in this batch   (0,-inf)\n",
    "\n",
    "    \n",
    "    return input_ids_tensor_train, batch_label_index, padding_mask     #  (b,4,512) (b,L) (b,L)  L is the largest length in this batch \n",
    "\n",
    "\n",
    "train_dataset = Dataset_transformer(input_ids_tensor_train, train_label_index_list)\n",
    "validation_dataset = Dataset_transformer(input_ids_tensor_validation, validation_label_index_list)\n",
    "batch_size_transformer = args.batch_size_transformer\n",
    "num_workers = args.num_workers\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size_transformer, shuffle=True, drop_last=True, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)  \n",
    "validation_dataloader = DataLoader(dataset=validation_dataset, batch_size=batch_size_transformer, shuffle=False, drop_last=False, num_workers=num_workers, collate_fn=collate_fn, pin_memory=True)\n",
    "decoder_num_layers = args.decoder_num_layers\n",
    "transformer_dropout = args.transformer_dropout\n",
    "transformer_nhead = args.transformer_nhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transformer_Model, self).__init__()\n",
    "\n",
    "        self.class_embeddings_start = torch.nn.Parameter(torch.randn(768))\n",
    "        self.class_embeddings_end_start = torch.nn.Parameter(torch.randn(768))\n",
    "\n",
    "        self.decoder_layer = torch.nn.TransformerDecoderLayer(d_model=768, nhead=transformer_nhead, dropout=transformer_dropout, activation='gelu', batch_first=True)\n",
    "        self.transformer_decoder = torch.nn.TransformerDecoder(self.decoder_layer, num_layers=decoder_num_layers)  # forward padding mask(N,L)  attention causal mask(L,L)  multiheadattention  is_causal\n",
    "\n",
    "        self.linear1 = torch.nn.Linear(768, 768)\n",
    "        self.gelu = torch.nn.GELU()\n",
    "        self.linear2 = torch.nn.Linear(768, 768)\n",
    "        self.softmax = torch.nn.Softmax()\n",
    "\n",
    "    def forward(self, class_embeddings_dict, mask_dict, batch_text_embedding_tensor, batch_label_index, attention_mask, batch_padding_mask):   #  (b,4,768), (b,L)  (b,L)\n",
    "\n",
    "        class_embeddings_dict = functions.add_end_classes_embeddings(class_embeddings_dict, self.class_embeddings_start, self.class_embeddings_end_start, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease, device)\n",
    "        class_embedding_list = []\n",
    "        for item in list(mask_dict.keys())[:-1]:\n",
    "            class_embedding_list.append(class_embeddings_dict[item])\n",
    "        class_embeddings_tensor = torch.stack(class_embedding_list)    # (C,768) C:17391\n",
    "\n",
    "        label_embedding_tensor = functions.convert_sequencial_label_to_embedding_tensor(batch_label_index, class_embeddings_dict, index_to_class_label_dict)  # (b,L) --> (b,L,768)\n",
    "        decoder_output = self.transformer_decoder(label_embedding_tensor, batch_text_embedding_tensor, tgt_mask=attention_mask , tgt_key_padding_mask=batch_padding_mask)#  (b,L,768)  (b,4,768) -->  (b,L,768)\n",
    "\n",
    "        transformer_output = self.linear1(decoder_output)   #  (b,L,768)\n",
    "        transformer_output = self.gelu(transformer_output)\n",
    "        transformer_output = self.linear2(transformer_output)  #  (b,L,768)\n",
    "\n",
    "        transformer_output = torch.nn.functional.normalize(transformer_output, dim=-1)  # (b,L,768)\n",
    "        class_embeddings_tensor = torch.nn.functional.normalize(class_embeddings_tensor, dim=-1)  #  (C,768)\n",
    "\n",
    "        # score_tensor = torch.nn.functional.cosine_similarity(transformer_output.unsqueeze(0).permute((1,0,2)), class_embeddings_tensor.unsqueeze(0), dim=-1)  # (L,1,768) (1,C,768) --> (L,C)\n",
    "        score_tensor = torch.matmul(transformer_output, class_embeddings_tensor.T)  # (b,L,768), (768,C)  -->  (b,L,C)\n",
    "        batch_mask_list = []\n",
    "        for item in batch_label_index:  # (b,L)\n",
    "            batch_mask_list.append(torch.stack([mask_dict[index_to_class_label_dict[index.item()]] for index in item]))   # (L,C)\n",
    "        batch_mask_tensor = torch.stack(batch_mask_list)   # (b,L,C)\n",
    "        batch_mask_tensor = batch_mask_tensor.to(device)\n",
    "        logits = (score_tensor+batch_mask_tensor)   # (b,L,C)\n",
    "        return logits  # (b,L,C)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = Transformer_Model()\n",
    "transformer_model = transformer_model.to(device)\n",
    "learning_rate = args.learning_rate\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum', ignore_index=17391)    # when compute, the size must be (N, C, L) and (N, L)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=learning_rate, weight_decay=args.adam_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(validation_dataloader):\n",
    "    transformer_model.eval()\n",
    "    print('Validation start...')\n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        category_accuracy = 0\n",
    "        first_class_accuracy = 0\n",
    "        second_class_accuracy = 0\n",
    "        disease_accuracy = 0\n",
    "        label_f1_0_1_tensor = torch.tensor([])\n",
    "        predicted_f1_0_1_tensor = torch.tensor([])\n",
    "        label_AUROC_tesnor = torch.tensor([],dtype=int).to(device)\n",
    "        predicted_AUROC_tensor = torch.tensor([]).to(device)\n",
    "        random_outout_index = random.randint(0,1000)\n",
    "        for i, (batch_input_ids_tensor_valid, batch_label_index, batch_padding_mask) in tqdm(enumerate(validation_dataloader)):\n",
    "\n",
    "            batch_input_ids_tensor_valid = batch_input_ids_tensor_valid.to(device, non_blocking=True)\n",
    "            batch_label_index = batch_label_index.to(device, non_blocking=True)\n",
    "            batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)\n",
    "\n",
    "            batch_text_embedding_tensor_valid = torch.stack([clinical_Bert_Model(single_input_ids_tensor_valid) for single_input_ids_tensor_valid in batch_input_ids_tensor_valid])  # (b,4,768)\n",
    "            attention_mask_valid = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)   # masked is True, not masked is False\n",
    "            \n",
    "            batch_logits = transformer_model(class_embeddings_dict, mask_dict, batch_text_embedding_tensor=batch_text_embedding_tensor_valid, batch_label_index=batch_label_index, attention_mask=attention_mask_valid, batch_padding_mask=batch_padding_mask)   # (b,4,768), (b,L) --> (b,L,C)\n",
    "            batch_logits = batch_logits.permute((0,2,1))    # --> (b,C,L)\n",
    "            end_start_index_label = class_label_index_dict['/start'] \n",
    "            lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "            validation_loss += criterion(batch_logits, lable_for_loss_tensor)\n",
    "\n",
    "            for j in range(batch_input_ids_tensor_valid.shape[0]):\n",
    "                \n",
    "                single_text_embedding_tensor_valid = batch_text_embedding_tensor_valid[j].unsqueeze(0)   # (1,4,768)\n",
    "\n",
    "                single_label_index_list = batch_label_index[j].tolist()    # [L]\n",
    "                padding_index = single_label_index_list.index(17391) if 17391 in single_label_index_list else len(single_label_index_list)\n",
    "                single_label_index_list = single_label_index_list[:padding_index]\n",
    "                single_sequencial_label = [index_to_class_label_dict[index] for index in single_label_index_list]\n",
    "\n",
    "                # ingle_label_index_tensor = label_index_list[j].unsqueeze(0)    # (1,L)\n",
    "                # single_text_embedding_tensor = single_text_embedding_tensor.to(device)\n",
    "                # single_label_index_tensor = single_label_index_tensor.to(device)\n",
    "\n",
    "                predicted_index_list = []\n",
    "                predicted_token_list = []\n",
    "                predicted_token_probabiluty_list = []\n",
    "                input_token_index_list = [class_label_index_dict['start']]\n",
    "                end_start_index_label = class_label_index_dict['/start'] \n",
    "                while input_token_index_list[-1] != end_start_index_label:\n",
    "                    logits = transformer_model(class_embeddings_dict, mask_dict, batch_text_embedding_tensor=single_text_embedding_tensor_valid, batch_label_index=torch.tensor([input_token_index_list]).to(device, non_blocking=True), attention_mask=None, batch_padding_mask=None)   # (1,4,768), (1,L) --> (1,L,C)\n",
    "                    predicted_index = torch.argmax(logits.squeeze(0), dim=-1)[-1].item()   # (1,L,C)-->int\n",
    "                    predicted_token_probabiluty_list.append(logits.squeeze(0)[-1])  # (1,L,C) -->[L,(C)]\n",
    "                    predicted_index_list.append(predicted_index)   # [L]\n",
    "                    predicted_token_list.append(index_to_class_label_dict[predicted_index])  # [L]\n",
    "                    input_token_index_list.append(predicted_index)   # [L]\n",
    "\n",
    "                    if len(predicted_token_list) > 150:\n",
    "                        break\n",
    "\n",
    "                predicted_token_probabiluty_tensor = torch.nn.Softmax(dim=-1)(torch.stack(predicted_token_probabiluty_list))  # (L,C)\n",
    "                predicted_category_tokens_list, predicted_first_class_tokens_list, predicted_second_class_tokens_list, predicted_disease_tokens_list = functions.split_predicted_class_tokens(predicted_token_list, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                label_category_tokens_list, label_first_class_tokens_list, label_second_class_tokens_list, label_disease_tokens_list = functions.split_predicted_class_tokens(single_sequencial_label, tree_dict_start_to_category, tree_dict_category_to_first_subclass, tree_dict_first_subclass_to_second_subclass, tree_dict_second_subclass_to_disease)\n",
    "                category_accuracy += (len(set(predicted_category_tokens_list).intersection(set(label_category_tokens_list))) / max(len(predicted_category_tokens_list), len(label_category_tokens_list)))\n",
    "                first_class_accuracy += (len(set(predicted_first_class_tokens_list).intersection(set(label_first_class_tokens_list))) / max(len(predicted_first_class_tokens_list), len(label_first_class_tokens_list)))\n",
    "                second_class_accuracy += (len(set(predicted_second_class_tokens_list).intersection(set(label_second_class_tokens_list))) / max(len(predicted_second_class_tokens_list), len(label_second_class_tokens_list)))\n",
    "                disease_accuracy += (len(set(predicted_disease_tokens_list).intersection(set(label_disease_tokens_list))) / max(len(predicted_disease_tokens_list), len(label_disease_tokens_list)))\n",
    "\n",
    "                single_label_f1_0_1_tensor, single_predicted_f1_0_1_tensor = functions.create_0_1_tensor_for_f1(single_sequencial_label, predicted_disease_tokens_list)\n",
    "                label_f1_0_1_tensor = torch.cat([label_f1_0_1_tensor, single_label_f1_0_1_tensor])\n",
    "                predicted_f1_0_1_tensor = torch.cat([predicted_f1_0_1_tensor, single_predicted_f1_0_1_tensor])\n",
    "\n",
    "                single_probability_AUROC_predicted, single_label_AUROC_0_1_tensor = functions.create_probability_tensor_for_AUROC(single_sequencial_label, class_label_index_dict, predicted_token_probabiluty_tensor, predicted_index_list, device)\n",
    "                label_AUROC_tesnor = torch.cat([label_AUROC_tesnor, single_label_AUROC_0_1_tensor.to(device).type(torch.int)])\n",
    "                predicted_AUROC_tensor = torch.cat([predicted_AUROC_tensor, single_probability_AUROC_predicted])\n",
    "\n",
    "                if 8*i+j == random_outout_index:\n",
    "                    print('label: ', single_sequencial_label)\n",
    "                    print('predicted: ', predicted_token_list)\n",
    "\n",
    "\n",
    "\n",
    "        label_f1_0_1_tensor = label_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        predicted_f1_0_1_tensor = predicted_f1_0_1_tensor.reshape((df_validation_top500.shape[0], 14567))  # (N, C)\n",
    "        valid_f1_micro = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='micro', multidim_average='global')\n",
    "        valid_f1_weighted = torchmetrics.functional.classification.multilabel_f1_score(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, threshold=0.5, average='weighted', multidim_average='global')\n",
    "\n",
    "\n",
    "        label_AUROC_tesnor = label_AUROC_tesnor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        predicted_AUROC_tensor = predicted_AUROC_tensor.reshape((df_validation_top500.shape[0], 17391))  # (N, C)\n",
    "        valid_AUROC_micro = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='micro')\n",
    "        valid_AUROC_weighted = torchmetrics.functional.classification.multilabel_auroc(predicted_AUROC_tensor, label_AUROC_tesnor, num_labels=17391, average='weighted')\n",
    "\n",
    "        valid_precision_micro = torchmetrics.functional.classification.multilabel_precision(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "        valid_recall_micro = torchmetrics.functional.classification.multilabel_recall(predicted_f1_0_1_tensor, label_f1_0_1_tensor, num_labels=14567, multidim_average='global', average='micro')\n",
    "\n",
    "    return validation_loss/df_validation_top500.shape[0], category_accuracy/df_validation_top500.shape[0], first_class_accuracy/df_validation_top500.shape[0], second_class_accuracy/df_validation_top500.shape[0], disease_accuracy/df_validation_top500.shape[0], valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(train_dataloader, validation_dataloader, epochs=5):\n",
    "\n",
    "    # config = { 'batch_size': batch_size_transformer, 'lr':learning_rate, 'loss':'CrossEntropyLoss', 'optim':'Adam', \n",
    "    #           'transformer_decoder_nhead':8, 'transformer_decoder_layers':decoder_num_layers, 'linear_layer':'768-768-Gelu-768', 'epochs':epochs}\n",
    "    # wandb.init(project=\"Result\", entity=\"htc-mimic3\", config=config)\n",
    "\n",
    "    print('Training start...')\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch: {epoch+1}')\n",
    "        loss_training_epoch = 0\n",
    "\n",
    "        transformer_model.train()\n",
    "        for i, (batch_input_ids_tensor_train, batch_label_index, batch_padding_mask) in tqdm(enumerate(train_dataloader)):\n",
    "            loss_training_batch = 0\n",
    "\n",
    "            batch_input_ids_tensor_train = batch_input_ids_tensor_train.to(device, non_blocking=True)   #  (b,4,512)\n",
    "            batch_label_index = batch_label_index.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "            batch_padding_mask = batch_padding_mask.to(device, non_blocking=True)  # (b,L)  L is the largest length in this batch \n",
    "\n",
    "            batch_text_embedding_tensor = torch.stack([clinical_Bert_Model(single_input_ids_tensor_train) for single_input_ids_tensor_train in batch_input_ids_tensor_train])\n",
    "            # (b,4,768)\n",
    "            attention_mask_train = torch.triu(torch.full((batch_padding_mask.shape[1], batch_padding_mask.shape[1]), True), diagonal=1).to(device, non_blocking=True)\n",
    "             # masked is True, not masked is False\n",
    "            batch_logits = transformer_model(class_embeddings_dict, mask_dict, batch_text_embedding_tensor=batch_text_embedding_tensor, batch_label_index=batch_label_index, attention_mask=attention_mask_train, batch_padding_mask=batch_padding_mask)   # (b,4,768), (b,L) --> (b,L,C)\n",
    "            batch_logits = batch_logits.permute((0,2,1))    # --> (b,C,L)\n",
    "            end_start_index_label = class_label_index_dict['/start'] \n",
    "            lable_for_loss_tensor = functions.create_lable_for_loss_tensor(batch_label_index, end_start_index_label, device) # (b,L)\n",
    "            loss_training_batch = criterion(batch_logits, lable_for_loss_tensor)  # (b,C,L), (b,L) --> tensor\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_training_batch.backward()\n",
    "            optimizer.step()         \n",
    "            loss_training_epoch += loss_training_batch.item()\n",
    "\n",
    "            \n",
    "\n",
    "        \n",
    "        print('the training loss in epoch',epoch+1,'is:',loss_training_epoch/df_train_top500.shape[0])\n",
    "        validation_loss, category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy, valid_f1_micro, valid_f1_weighted, valid_AUROC_micro, valid_AUROC_weighted, valid_precision_micro, valid_recall_micro= valid(validation_dataloader)\n",
    "        # wandb.log({'training_loss': loss_training_epoch/df_train_top500.shape[0]})\n",
    "        # wandb.log({'validation_loss': validation_loss.item()})\n",
    "        # wandb.log({'valid_category_accuracy': category_accuracy})\n",
    "        # wandb.log({'valid_first_class_accuracy': first_class_accuracy})\n",
    "        # wandb.log({'valid_second_class_accuracy': second_class_accuracy})\n",
    "        # wandb.log({'valid_disease_accuracy': disease_accuracy})\n",
    "        # wandb.log({'valid_f1_micro': valid_f1_micro.item()})\n",
    "        # wandb.log({'valid_f1_weighted': valid_f1_weighted.item()})\n",
    "        # wandb.log({'valid_AUROC_micro': valid_AUROC_micro.item()})\n",
    "        # wandb.log({'valid_AUROC_weighted': valid_AUROC_weighted.item()})\n",
    "        # wandb.log({'valid_precision_micro': valid_precision_micro.item()})\n",
    "        # wandb.log({'valid_recall_micro': valid_recall_micro.item()})\n",
    "\n",
    "        print('the valid loss in epoch',epoch+1,'is:', validation_loss.item())\n",
    "        print('the valid accuracy in epoch',epoch+1,'is:', category_accuracy, first_class_accuracy, second_class_accuracy, disease_accuracy)\n",
    "        print('the valid f1 micro in epoch',epoch+1,'is:', valid_f1_micro.item())\n",
    "        print('the valid f1 weighted in epoch',epoch+1,'is:', valid_f1_weighted.item())\n",
    "        print('the valid AUROC micro in epoch',epoch+1,'is:', valid_AUROC_micro.item())\n",
    "        print('the valid AUROC weighted in epoch',epoch+1,'is:', valid_AUROC_weighted.item())\n",
    "        print('the valid_precision micro in epoch',epoch+1,'is:', valid_precision_micro.item())\n",
    "        print('the valid_recall_micro weighted in epoch',epoch+1,'is:', valid_recall_micro.item())\n",
    "    \n",
    "    print('Training Finished')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mranniu\u001b[0m (\u001b[33mhtc-mimic3\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/u/home/niur/htc_mimic3/wandb/run-20230424_131410-rdyc60ri</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/htc-mimic3/Result/runs/rdyc60ri\" target=\"_blank\">divine-tree-6</a></strong> to <a href=\"https://wandb.ai/htc-mimic3/Result\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start...\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [25:52,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 1 is: 90.04556358466714\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [17:57,  5.73s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 1 is: 87.63531494140625\n",
      "the valid accuracy in epoch 1 is: 0.2927451973951964 0.11471610200658165 0.05937162716024962 0.002875035694153341\n",
      "the valid f1 micro in epoch 1 is: 0.005934718064963818\n",
      "the valid f1 weighted in epoch 1 is: 0.00184868392534554\n",
      "the valid AUROC micro in epoch 1 is: 0.5474229454994202\n",
      "the valid AUROC weighted in epoch 1 is: 0.5095553994178772\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [25:59,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 2 is: 89.05736853892296\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [14:17,  4.56s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 2 is: 87.02941131591797\n",
      "the valid accuracy in epoch 2 is: 0.3224152625152608 0.12762710633306582 0.0547350297707111 0.032170506437147466\n",
      "the valid f1 micro in epoch 2 is: 0.06586217135190964\n",
      "the valid f1 weighted in epoch 2 is: 0.018644947558641434\n",
      "the valid AUROC micro in epoch 2 is: 0.5563565492630005\n",
      "the valid AUROC weighted in epoch 2 is: 0.509868860244751\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:59,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 3 is: 88.60121428135874\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [13:38,  4.35s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 3 is: 86.68770599365234\n",
      "the valid accuracy in epoch 3 is: 0.3127272394272379 0.13162564390660328 0.06902970936871891 0.03074382293546395\n",
      "the valid f1 micro in epoch 3 is: 0.06485217809677124\n",
      "the valid f1 weighted in epoch 3 is: 0.018714966252446175\n",
      "the valid AUROC micro in epoch 3 is: 0.5568458437919617\n",
      "the valid AUROC weighted in epoch 3 is: 0.5130043625831604\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 4 is: 88.2790842253834\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [15:35,  4.98s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 4 is: 86.44109344482422\n",
      "the valid accuracy in epoch 4 is: 0.33810134495134364 0.14369535105131045 0.07350329655151663 0.03242201441103395\n",
      "the valid f1 micro in epoch 4 is: 0.06773848086595535\n",
      "the valid f1 weighted in epoch 4 is: 0.01992989517748356\n",
      "the valid AUROC micro in epoch 4 is: 0.5635867118835449\n",
      "the valid AUROC weighted in epoch 4 is: 0.5163973569869995\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:59,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 5 is: 88.04717087970167\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [12:37,  4.03s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 5 is: 86.24073028564453\n",
      "the valid accuracy in epoch 5 is: 0.2844327635327624 0.12237878555053452 0.06430974846160624 0.02989142005511988\n",
      "the valid f1 micro in epoch 5 is: 0.06425285339355469\n",
      "the valid f1 weighted in epoch 5 is: 0.019109394401311874\n",
      "the valid AUROC micro in epoch 5 is: 0.5517024993896484\n",
      "the valid AUROC weighted in epoch 5 is: 0.5094125270843506\n",
      "Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 6 is: 87.83772927623684\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [15:26,  4.93s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 6 is: 86.06600189208984\n",
      "the valid accuracy in epoch 6 is: 0.32601903836903695 0.13676738364834298 0.07203548839361561 0.03847539583353309\n",
      "the valid f1 micro in epoch 6 is: 0.07955368608236313\n",
      "the valid f1 weighted in epoch 6 is: 0.024859094992280006\n",
      "the valid AUROC micro in epoch 6 is: 0.561206579208374\n",
      "the valid AUROC weighted in epoch 6 is: 0.5155806541442871\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 7 is: 87.64991688414032\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [14:53,  4.75s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 7 is: 85.86820220947266\n",
      "the valid accuracy in epoch 7 is: 0.31838911088910915 0.14414064369296525 0.07891189432629095 0.045316163789770846\n",
      "the valid f1 micro in epoch 7 is: 0.08953505009412766\n",
      "the valid f1 weighted in epoch 7 is: 0.03942258283495903\n",
      "the valid AUROC micro in epoch 7 is: 0.5628231167793274\n",
      "the valid AUROC weighted in epoch 7 is: 0.5220209360122681\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 8 is: 87.46542015003844\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [13:46,  4.39s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 8 is: 85.74016571044922\n",
      "the valid accuracy in epoch 8 is: 0.2979548174048163 0.1302973083532677 0.07214192173495601 0.03940170760325582\n",
      "the valid f1 micro in epoch 8 is: 0.07856620103120804\n",
      "the valid f1 weighted in epoch 8 is: 0.03372402489185333\n",
      "the valid AUROC micro in epoch 8 is: 0.5560683012008667\n",
      "the valid AUROC weighted in epoch 8 is: 0.5167094469070435\n",
      "Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [24:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 9 is: 87.2994159870902\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [21:01,  6.71s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 9 is: 85.58448028564453\n",
      "the valid accuracy in epoch 9 is: 0.3220792744292731 0.1903950161723374 0.10731093221650496 0.06539251483523943\n",
      "the valid f1 micro in epoch 9 is: 0.11697632074356079\n",
      "the valid f1 weighted in epoch 9 is: 0.07306212931871414\n",
      "the valid AUROC micro in epoch 9 is: 0.5792462229728699\n",
      "the valid AUROC weighted in epoch 9 is: 0.5352982878684998\n",
      "Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [24:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 10 is: 87.14449847305787\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [17:50,  5.69s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 10 is: 85.40869140625\n",
      "the valid accuracy in epoch 10 is: 0.3049844544344533 0.17922215850311762 0.10532859942202052 0.06605019885801634\n",
      "the valid f1 micro in epoch 10 is: 0.11856560409069061\n",
      "the valid f1 weighted in epoch 10 is: 0.0761110782623291\n",
      "the valid AUROC micro in epoch 10 is: 0.5731008648872375\n",
      "the valid AUROC weighted in epoch 10 is: 0.5320634841918945\n",
      "Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 11 is: 86.99758535769475\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [21:17,  6.79s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 11 is: 85.2469711303711\n",
      "the valid accuracy in epoch 11 is: 0.34171488511488346 0.21518607295124256 0.1321442265909758 0.08588809440946682\n",
      "the valid f1 micro in epoch 11 is: 0.14510872960090637\n",
      "the valid f1 weighted in epoch 11 is: 0.09008853882551193\n",
      "the valid AUROC micro in epoch 11 is: 0.5868446826934814\n",
      "the valid AUROC weighted in epoch 11 is: 0.5425281524658203\n",
      "Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [24:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 12 is: 86.84521627695547\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [24:22,  7.78s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 12 is: 85.14347076416016\n",
      "the valid accuracy in epoch 12 is: 0.3936280719280717 0.2335059740053543 0.1301735697423775 0.07495896362739495\n",
      "the valid f1 micro in epoch 12 is: 0.12953267991542816\n",
      "the valid f1 weighted in epoch 12 is: 0.08647783100605011\n",
      "the valid AUROC micro in epoch 12 is: 0.5949451327323914\n",
      "the valid AUROC weighted in epoch 12 is: 0.5471138954162598\n",
      "Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 13 is: 86.70681539991706\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [25:26,  8.12s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 13 is: 84.99137878417969\n",
      "the valid accuracy in epoch 13 is: 0.40843783623783586 0.25878568623212506 0.1459189157219342 0.0911521743640267\n",
      "the valid f1 micro in epoch 13 is: 0.15029264986515045\n",
      "the valid f1 weighted in epoch 13 is: 0.09438081085681915\n",
      "the valid AUROC micro in epoch 13 is: 0.6032176613807678\n",
      "the valid AUROC weighted in epoch 13 is: 0.5533795356750488\n",
      "Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 14 is: 86.57196745360639\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [25:57,  8.28s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 14 is: 84.88902282714844\n",
      "the valid accuracy in epoch 14 is: 0.4170714581714579 0.25182780100876023 0.1445873655870559 0.08849285764875015\n",
      "the valid f1 micro in epoch 14 is: 0.13990581035614014\n",
      "the valid f1 weighted in epoch 14 is: 0.09492061287164688\n",
      "the valid AUROC micro in epoch 14 is: 0.5996712446212769\n",
      "the valid AUROC weighted in epoch 14 is: 0.5533708333969116\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:52,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 15 is: 86.44574242931301\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [23:05,  7.37s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 15 is: 84.77910614013672\n",
      "the valid accuracy in epoch 15 is: 0.4246034687534691 0.2577821891845106 0.14194778113756434 0.08584704198350733\n",
      "the valid f1 micro in epoch 15 is: 0.14146466553211212\n",
      "the valid f1 weighted in epoch 15 is: 0.094391830265522\n",
      "the valid AUROC micro in epoch 15 is: 0.5998722314834595\n",
      "the valid AUROC weighted in epoch 15 is: 0.5550144910812378\n",
      "Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 16 is: 86.31744409909581\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [22:52,  7.30s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 16 is: 84.65512084960938\n",
      "the valid accuracy in epoch 16 is: 0.3649950438450431 0.24004127574065592 0.13797347220775988 0.0853491073615318\n",
      "the valid f1 micro in epoch 16 is: 0.14249660074710846\n",
      "the valid f1 weighted in epoch 16 is: 0.09574858099222183\n",
      "the valid AUROC micro in epoch 16 is: 0.5940213799476624\n",
      "the valid AUROC weighted in epoch 16 is: 0.550326406955719\n",
      "Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 17 is: 86.18916177839434\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [24:59,  7.98s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 17 is: 84.5443344116211\n",
      "the valid accuracy in epoch 17 is: 0.43342761497761484 0.273878594902975 0.16144118374458918 0.09909470032592253\n",
      "the valid f1 micro in epoch 17 is: 0.15800125896930695\n",
      "the valid f1 weighted in epoch 17 is: 0.10828565061092377\n",
      "the valid AUROC micro in epoch 17 is: 0.6061996221542358\n",
      "the valid AUROC weighted in epoch 17 is: 0.5642481446266174\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:54,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 18 is: 86.07472093944945\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [27:18,  8.72s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 18 is: 84.43937683105469\n",
      "the valid accuracy in epoch 18 is: 0.38952227587227556 0.26883852975369915 0.16322527417829258 0.10471515031037171\n",
      "the valid f1 micro in epoch 18 is: 0.1642410308122635\n",
      "the valid f1 weighted in epoch 18 is: 0.11270958185195923\n",
      "the valid AUROC micro in epoch 18 is: 0.6064586639404297\n",
      "the valid AUROC weighted in epoch 18 is: 0.5583986639976501\n",
      "Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [24:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 19 is: 85.96589892328122\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [32:18, 10.31s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 19 is: 84.3272933959961\n",
      "the valid accuracy in epoch 19 is: 0.46354012654012583 0.2991644331388131 0.16929736058861436 0.10584770739510603\n",
      "the valid f1 micro in epoch 19 is: 0.16217197477817535\n",
      "the valid f1 weighted in epoch 19 is: 0.1109151616692543\n",
      "the valid AUROC micro in epoch 19 is: 0.618847131729126\n",
      "the valid AUROC weighted in epoch 19 is: 0.5681014060974121\n",
      "Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:59,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 20 is: 85.86521419877162\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [23:49,  7.60s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 20 is: 84.2478256225586\n",
      "the valid accuracy in epoch 20 is: 0.39614559699559665 0.25291165567318713 0.14131722454818418 0.08697788413084567\n",
      "the valid f1 micro in epoch 20 is: 0.1471722424030304\n",
      "the valid f1 weighted in epoch 20 is: 0.09821538627147675\n",
      "the valid AUROC micro in epoch 20 is: 0.5976758599281311\n",
      "the valid AUROC weighted in epoch 20 is: 0.5553144216537476\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 21 is: 85.74467650375797\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [29:04,  9.28s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 21 is: 84.19354248046875\n",
      "the valid accuracy in epoch 21 is: 0.4503984903984909 0.3024386469567577 0.18513515116061527 0.11967898118194235\n",
      "the valid f1 micro in epoch 21 is: 0.18134526908397675\n",
      "the valid f1 weighted in epoch 21 is: 0.12240415066480637\n",
      "the valid AUROC micro in epoch 21 is: 0.6184165477752686\n",
      "the valid AUROC weighted in epoch 21 is: 0.5688403844833374\n",
      "Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 22 is: 85.64968192465112\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [24:38,  7.87s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 22 is: 84.07875061035156\n",
      "the valid accuracy in epoch 22 is: 0.4189823213823206 0.28638981581713724 0.16601403586666744 0.1063934047309535\n",
      "the valid f1 micro in epoch 22 is: 0.16674001514911652\n",
      "the valid f1 weighted in epoch 22 is: 0.1130625307559967\n",
      "the valid AUROC micro in epoch 22 is: 0.6076703667640686\n",
      "the valid AUROC weighted in epoch 22 is: 0.562142550945282\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:56,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 23 is: 85.55201833261609\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [32:22, 10.33s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 23 is: 83.99308776855469\n",
      "the valid accuracy in epoch 23 is: 0.48449681429681385 0.34037125224563247 0.19929844931470297 0.12998790157584725\n",
      "the valid f1 micro in epoch 23 is: 0.1933782547712326\n",
      "the valid f1 weighted in epoch 23 is: 0.12938514351844788\n",
      "the valid AUROC micro in epoch 23 is: 0.6315803527832031\n",
      "the valid AUROC weighted in epoch 23 is: 0.5776476860046387\n",
      "Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 24 is: 85.44341680379462\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [26:20,  8.41s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 24 is: 83.89922332763672\n",
      "the valid accuracy in epoch 24 is: 0.43849502719502703 0.3028865458701367 0.17986623140934277 0.11432043988663643\n",
      "the valid f1 micro in epoch 24 is: 0.17685386538505554\n",
      "the valid f1 weighted in epoch 24 is: 0.11771706491708755\n",
      "the valid AUROC micro in epoch 24 is: 0.6139652729034424\n",
      "the valid AUROC weighted in epoch 24 is: 0.5684491395950317\n",
      "Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 25 is: 85.34887414059396\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [28:09,  8.99s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 25 is: 83.81151580810547\n",
      "the valid accuracy in epoch 25 is: 0.4553106837606836 0.29722108886125825 0.1781327276180988 0.11219276589124798\n",
      "the valid f1 micro in epoch 25 is: 0.1732216626405716\n",
      "the valid f1 weighted in epoch 25 is: 0.11766167730093002\n",
      "the valid AUROC micro in epoch 25 is: 0.6172930002212524\n",
      "the valid AUROC weighted in epoch 25 is: 0.568454384803772\n",
      "Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:58,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 26 is: 85.25293913085133\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [32:23, 10.34s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 26 is: 83.77603912353516\n",
      "the valid accuracy in epoch 26 is: 0.46500070115070186 0.3403046746415259 0.2105068518646017 0.13166511729858396\n",
      "the valid f1 micro in epoch 26 is: 0.19735145568847656\n",
      "the valid f1 weighted in epoch 26 is: 0.13812156021595\n",
      "the valid AUROC micro in epoch 26 is: 0.6341274380683899\n",
      "the valid AUROC weighted in epoch 26 is: 0.5777596831321716\n",
      "Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [24:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 27 is: 85.15281228246886\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [31:01,  9.90s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 27 is: 83.62098693847656\n",
      "the valid accuracy in epoch 27 is: 0.4884008232508229 0.34098980934213063 0.2073741044587791 0.13149375567274318\n",
      "the valid f1 micro in epoch 27 is: 0.1967349797487259\n",
      "the valid f1 weighted in epoch 27 is: 0.13943196833133698\n",
      "the valid AUROC micro in epoch 27 is: 0.6310782432556152\n",
      "the valid AUROC weighted in epoch 27 is: 0.5835151672363281\n",
      "Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 28 is: 85.06513254700856\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [26:49,  8.56s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 28 is: 83.56132507324219\n",
      "the valid accuracy in epoch 28 is: 0.46147525807525835 0.31892612765344913 0.19327724490565037 0.12086061740105011\n",
      "the valid f1 micro in epoch 28 is: 0.18425090610980988\n",
      "the valid f1 weighted in epoch 28 is: 0.13023976981639862\n",
      "the valid AUROC micro in epoch 28 is: 0.619475781917572\n",
      "the valid AUROC weighted in epoch 28 is: 0.5753476619720459\n",
      "Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:57,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 29 is: 84.96603656488624\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [30:40,  9.79s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 29 is: 83.4811019897461\n",
      "the valid accuracy in epoch 29 is: 0.46533261738261733 0.3388451915129926 0.2105817112597293 0.13810578147044\n",
      "the valid f1 micro in epoch 29 is: 0.20360900461673737\n",
      "the valid f1 weighted in epoch 29 is: 0.13561096787452698\n",
      "the valid AUROC micro in epoch 29 is: 0.6303483843803406\n",
      "the valid AUROC weighted in epoch 29 is: 0.5784757137298584\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1062it [23:55,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training loss in epoch 30 is: 84.88639604888169\n",
      "Validation start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "188it [27:19,  8.72s/it]\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No negative samples in targets, false positive value should be meaningless. Returning zero tensor in false positive score\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/u/home/niur/venv_1/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the valid loss in epoch 30 is: 83.40372467041016\n",
      "the valid accuracy in epoch 30 is: 0.42448636178636223 0.2940718078991288 0.1936086626307985 0.12380353206678746\n",
      "the valid f1 micro in epoch 30 is: 0.18772165477275848\n",
      "the valid f1 weighted in epoch 30 is: 0.13539527356624603\n",
      "the valid AUROC micro in epoch 30 is: 0.6181236505508423\n",
      "the valid AUROC weighted in epoch 30 is: 0.5746471285820007\n",
      "Training Finished\n"
     ]
    }
   ],
   "source": [
    "# mp.set_start_method('spawn',force=True)\n",
    "train(train_dataloader, validation_dataloader, epochs=args.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click  argparse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2987113b9c300c1ae8cab2be01e277860fb941e8f6dd0f5e5312227dbdee95ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
